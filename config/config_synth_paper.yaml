# Stale-prior theoretical trap experiment (synthetic).

plot_shift: 1
plot_target: "y"

environment:
  # Dataset / experiment
  data_source: synthetic
  setting: theoretical_trap
  # Tweak: total time steps.
  T: 3000
  seed: 42

  # Dimensions
  # Tweak: number of experts and regimes.
  num_experts: 3
  num_regimes: 2
  state_dim: 1

  # Special setting implemented in synthetic_env.py that constructs:
  #   - Regime 0 (good times): experts 0 and 1 ~ 0, expert 2 ~ 1
  #   - Regime 1 (bad times):  experts 0 and 1 ~ 10, expert 2 ~ 1
  #   - Expert 1 goes offline during the start of the bad regime,
  #     creating a "stale prior" on its historical performance.

routers:
  # Global router settings
  # Tweak: risk sensitivity and per-expert consultation cost.
  beta: 0.0
  staleness_threshold: null

  # Factorized SLDS router (train on [1..em_tk], then deploy)
  factorized_slds:
    enabled: true
    num_regimes: 3
    shared_dim: 1
    idiosyncratic_dim: 1
    delta_max: 2000
    R_scalar: 0.5
    Q_g_scales: [0.02, 0.08, 0.04]
    Q_u_scales: [0.005, 0.015, 0.01]
    # Exploration mode for partial feedback:
    #   - "g": IDS using only shared-factor information (current default)
    #   - "g_z": IDS using joint (z, g) information
    #   - "ucb": Bayes-UCB (LCB) on predictive costs
    #   - "sampling": posterior sampling on predictive costs
    exploration: ["g_z", "g"]
    # Diagnostic: log I(z; e) estimates to verify g vs g_z differences.
    exploration_diag_enabled: true
    exploration_diag_stride: 200
    exploration_diag_samples: 50
    exploration_diag_print: true
    # Parallelize exploration runs across CPUs.
    parallel_exploration: true
    parallel_workers: null
    # Parallelize full pipelines per exploration mode.
    parallel_pipeline: true
    parallel_pipeline_workers: 8
    parallel_pipeline_disable_plot_show: true

    em_enabled: true
    # If true, offline EM uses full feedback even for partial routers.
    em_offline_full_feedback: true
    em_tk: 300 #1200
    em_n: 10
    em_samples: 8
    em_burn_in: 5
    # Offline EM runs without validation.
    em_val_fraction: 0.0
    em_val_len: null
    em_theta_lr: 0.005
    em_theta_steps: 1
    em_print_val_loss: true
    em_eps_n: 1.0e-3

    # Online (sliding-window) EM adaptation.
    em_online_enabled: false
    em_online_window: 1000
    em_online_period: 200
    em_online_n: 5
    em_online_samples: 8
    em_online_burn_in: 3
    em_online_theta_lr: 0.005
    em_online_theta_steps: 1
    em_online_eps_n: 1.0e-3
    em_online_print_val_loss: true
    # If null, defaults to em_tk + 1.
    em_online_start_t: null

    transition_mode: "attention"

baselines:
  l2d:
    arch: "mlp"
    # Very small learning rate so that the stale prior on Expert 1 from
    # Phase 1 is not quickly overwritten by a few bad pulls in Phase 3.
    learning_rate: 0.0005
    hidden_dim: 8
    window_size: 1
    alpha: 1.0
    beta: null

  l2d_sw:
    arch: "rnn"
    # Similarly slow adaptation for the sliding-window baseline.
    learning_rate: 0.0005
    hidden_dim: 8
    window_size: 200
    alpha: 1.0
    beta: null

  linucb:
    # Strong optimism so that the (stale) historical mean for Expert 1
    # dominates when it returns, triggering the trap.
    alpha_ucb: 1.0
    # Strong ridge prior so that a few bad pulls in Phase 3 do not
    # immediately erase the excellent Phase-1 history for Expert 1.
    lambda_reg: 1.0

  neural_ucb:
    # NeuralUCB baseline: we mirror the stale-prior regime by using
    # strong optimism and a slow-moving embedding.
    alpha_ucb: 1.0
    lambda_reg: 1.0
    hidden_dim: 16
    nn_learning_rate: 0.0001

horizon_planning:
  # Starting time index for horizon planning in slds_imm_router.py
  t0: 1200

  # Planning horizon length
  H: 100
  # Planning method for horizon scheduling:
  #   - "regressive": original router-influenced context planning
  #   - "monte_carlo": scenario-based staffing planning with N=1
  #   - "{N}_monte_carlo": N-scenario Monte Carlo staffing planning
  method: "20_monte_carlo"

  # Coverage tolerance delta for scheduling.
  delta: 0.1

  # Scenario generator parameters for Monte Carlo planning.
  # Gaussian AR(1) feature-space perturbation as in
  # Section~\ref{sec:staffing-generator-gaussian}.
  scenario_generator:
    type: "gaussian_ar1"
    # Max |rho| cap for the AR(1) coefficient fit on history.
    rho: 0.9
    # Initial innovation scale (multiplies fitted residual std).
    sigma0: 0.1
    # Per-step innovation scale (multiplies fitted residual std).
    q_scale: 0.1
    # Global scale on Monte Carlo context noise.
    noise_scale: 1.0
