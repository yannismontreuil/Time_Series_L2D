\appendix
\onecolumn
\section{Algorithms} \label{algo}

% =========================
% Algorithm 0: Parameter Learning
% =========================
\begin{algorithm}[H]
\caption{\textsc{LearnParameter\_EM}: Monte Carlo EM for the Factorized SLDS (windowed batch; includes $\theta$ for context-dependent transitions)}
\label{alg:trainmodel_em}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} index set $\mathcal{T}=\{t_a,\dots,t_b\}$; contexts $(\mathbf{x}_t)_{t\in\mathcal{T}}$; available sets $(\mathcal{E}_t)_{t\in\mathcal{T}}$; actions $(I_t)_{t\in\mathcal{T}}$; observed residuals $(e_t)_{t\in\mathcal{T}}$ with $e_t=y_t-\widehat{y}_{t,I_t}$; feature map $\phi$; EM iterations $N_{\mathrm{EM}}$; posterior samples $N_{\mathrm{samp}}$; burn-in $N_{\mathrm{burn}}$; occupancy floor $\epsilon_N>0$; MAP priors $(M^{(g)}_A,\lambda^{(g)}_A,\Psi^{(g)},\nu^{(g)})$, $(M^{(u)}_A,\lambda^{(u)}_A,\Psi^{(u)},\nu^{(u)})$, $(M_B,\lambda_B)$, $(a_R,b_R)$, and $\lambda_\theta$ for $\theta$ in $\Pi_\theta(\mathbf{x}_t)$.
\STATE $\mathcal{K}\leftarrow \bigcup_{t\in\mathcal{T}} \mathcal{E}_t$
\STATE {\bfseries Initialize:} parameters $\Theta^{(0)}$; initial state priors for $z_{t_a},\mathbf{g}_{t_a},\{\mathbf{u}_{t_a,k}\}_{k\in\mathcal{K}}$.
\FOR{iteration $i = 1$ to $N_{\mathrm{EM}}$}
    \STATE \textbf{// E-STEP: Monte Carlo posterior (blocked Gibbs)}
    \IF{$i=1$}
        \STATE Initialize $(z_{t_a:t_b},\mathbf{g}_{t_a:t_b},\{\mathbf{u}_{t_a:t_b,k}\}_{k\in\mathcal{K}})$ by sampling from the priors (or via a single smoothing pass under $\Theta^{(0)}$).
    \ELSE
        \STATE Initialize $(z_{t_a:t_b},\mathbf{g}_{t_a:t_b},\{\mathbf{u}_{t_a:t_b,k}\}_{k\in\mathcal{K}})$ from previous samples.
    \ENDIF
    \FOR{sample $s=1$ to $N_{\mathrm{burn}}+N_{\mathrm{samp}}$}
        \STATE \textbf{Sample $z_{t_a:t_b}^{(s)}$ via FFBS:} use transition $\Pi_\theta(\mathbf{x}_t)$ and ``local evidence''
        \[
        \ell_t^{(m)} \propto 
        p\!\left(e_t \mid z_t=m,\mathbf{g}_t^{(s-1)},\mathbf{u}_{t,I_t}^{(s-1)}\right)\,
        p\!\left(\mathbf{g}_t^{(s-1)}\mid \mathbf{g}_{t-1}^{(s-1)}, z_t=m\right)\,
        \prod_{k\in \mathcal{K}} p\!\left(\mathbf{u}_{t,k}^{(s-1)}\mid \mathbf{u}_{t-1,k}^{(s-1)}, z_t=m\right).
        \]
        \STATE \textbf{Sample $\mathbf{g}_{t_a:t_b}^{(s)}$ via Kalman smoothing} given $z_{t_a:t_b}^{(s)}$, $\{\mathbf{u}_{t_a:t_b,k}^{(s-1)}\}_{k\in\mathcal{K}}$, and bandit observations $\{e_t\}$ (missing for $k\neq I_t$).
        \FOR{each expert $k\in\mathcal{K}$}
            \STATE \textbf{Sample $\mathbf{u}_{t_a:t_b,k}^{(s)}$ via Kalman smoothing} given $z_{t_a:t_b}^{(s)}$, $\mathbf{g}_{t_a:t_b}^{(s)}$, and $\{e_t:I_t=k\}$ (missing otherwise).
        \ENDFOR
        \IF{$s>N_{\mathrm{burn}}$}
            \STATE Accumulate Monte Carlo sufficient statistics.
        \ENDIF
    \ENDFOR
    \STATE Form Monte Carlo responsibilities and transition counts:
    \[
    \gamma_t^{(m)}\coloneqq \frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\},\qquad
    \xi_{t-1}^{(\ell,m)}\coloneqq \frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_{t-1}^{(s)}=\ell,z_t^{(s)}=m\}.
    \]
    \STATE \textbf{// M-STEP: MAP closed-form updates}
    \STATE For each mode $m$, define (using MC averages)
    \[
    S^{(m)}_{g g^-}\coloneqq \sum_{t\in\mathcal{T}\setminus\{t_a\}}\frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\}\,\mathbf{g}_t^{(s)}\mathbf{g}_{t-1}^{(s)\top},
    \quad
    S^{(m)}_{g^- g^-}\coloneqq \sum_{t\in\mathcal{T}\setminus\{t_a\}}\frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\}\,\mathbf{g}_{t-1}^{(s)}\mathbf{g}_{t-1}^{(s)\top},
    \]
    \[
    N_m\coloneqq \sum_{t\in\mathcal{T}\setminus\{t_a\}}\gamma_t^{(m)}.
    \]
    \IF{$N_m \le \epsilon_N$}
        \STATE Keep $A_m^{(g)}$ and $Q_m^{(g)}$ unchanged.
    \ELSE
        \STATE $A_m^{(g)}\leftarrow\left(S^{(m)}_{g g^-}+\lambda^{(g)}_A M^{(g)}_A\right)\left(S^{(m)}_{g^- g^-}+\lambda^{(g)}_A I\right)^{-1}$.
        \STATE Define
        \[
        S^{(m)}_{g\mid g^-}\coloneqq
        \sum_{t\in\mathcal{T}\setminus\{t_a\}}\frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\}\,
        \left(\mathbf{g}_t^{(s)}-A_m^{(g)}\mathbf{g}_{t-1}^{(s)}\right)\left(\mathbf{g}_t^{(s)}-A_m^{(g)}\mathbf{g}_{t-1}^{(s)}\right)^\top.
        \]
        \STATE $Q_m^{(g)}\leftarrow\frac{\Psi^{(g)}+S^{(m)}_{g\mid g^-}}{\nu^{(g)}+N_m+d_g+1}$.
    \ENDIF

    \STATE For each mode $m$, define
    \[
    S^{(m)}_{u u^-}\coloneqq \sum_{t\in\mathcal{T}\setminus\{t_a\}}\sum_{k\in\mathcal{K}}\frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\}\,\mathbf{u}_{t,k}^{(s)}\mathbf{u}_{t-1,k}^{(s)\top},
    \]
    \[
    S^{(m)}_{u^- u^-}\coloneqq \sum_{t\in\mathcal{T}\setminus\{t_a\}}\sum_{k\in\mathcal{K}}\frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\}\,\mathbf{u}_{t-1,k}^{(s)}\mathbf{u}_{t-1,k}^{(s)\top},
    \]
    \[
    N_m^{(u)}\coloneqq \sum_{t\in\mathcal{T}\setminus\{t_a\}}\sum_{k\in\mathcal{K}}\gamma_t^{(m)}.
    \]
    \IF{$N_m^{(u)} \le \epsilon_N$}
        \STATE Keep $A_m^{(u)}$ and $Q_m^{(u)}$ unchanged.
    \ELSE
        \STATE $A_m^{(u)}\leftarrow\left(S^{(m)}_{u u^-}+\lambda^{(u)}_A M^{(u)}_A\right)\left(S^{(m)}_{u^- u^-}+\lambda^{(u)}_A I\right)^{-1}$.
        \STATE Define
        \[
        S^{(m)}_{u\mid u^-}\coloneqq
        \sum_{t\in\mathcal{T}\setminus\{t_a\}}\sum_{k\in\mathcal{K}}\frac{1}{N_{\mathrm{samp}}}\sum_{s=1}^{N_{\mathrm{samp}}}\mathbf{1}\{z_t^{(s)}=m\}\,
        \left(\mathbf{u}_{t,k}^{(s)}-A_m^{(u)}\mathbf{u}_{t-1,k}^{(s)}\right)\left(\mathbf{u}_{t,k}^{(s)}-A_m^{(u)}\mathbf{u}_{t-1,k}^{(s)}\right)^\top.
        \]
        \STATE $Q_m^{(u)}\leftarrow\frac{\Psi^{(u)}+S^{(m)}_{u\mid u^-}}{\nu^{(u)}+N_m^{(u)}+d_\alpha+1}$.
    \ENDIF

    \STATE For each expert $k$, compute $W_k\coloneqq \sum_{t\in\mathcal{T}:I_t=k}\sum_{m=1}^M \gamma_t^{(m)}$.
    \IF{$W_k \le \epsilon_N$}
        \STATE Keep $\mathbf{B}_k$ unchanged.
    \ELSE
        \STATE For $t$ with $I_t=k$, define $\phi_t\coloneqq \phi(\mathbf{x}_t)$ and
        \[
        y_{t}^{(m)}\coloneqq e_t-\phi_t^\top\,\mathbb{E}_m[\mathbf{u}_{t,k}],\qquad
        w_t^{(m)}\coloneqq \gamma_t^{(m)}/R_{m,k}.
        \]
        \STATE Let $\Sigma_{g,t}^{(m)}\coloneqq \mathbb{E}_m[\mathbf{g}_t\mathbf{g}_t^\top]$ and $\mu_{g,t}^{(m)}\coloneqq \mathbb{E}_m[\mathbf{g}_t]$.
        \STATE Define the (exact-EM) normal-equation matrices
        \[
        \mathcal{H}_k \coloneqq \sum_{t\in\mathcal{T}:I_t=k}\sum_{m=1}^M w_t^{(m)}\left(\Sigma_{g,t}^{(m)}\otimes(\phi_t\phi_t^\top)\right),\qquad
        \mathcal{b}_k \coloneqq \sum_{t\in\mathcal{T}:I_t=k}\sum_{m=1}^M w_t^{(m)}\left(\mu_{g,t}^{(m)}\otimes \phi_t\right)\, y_t^{(m)}.
        \]
        \STATE Update
        \[
        \mathrm{vec}(\mathbf{B}_k)\leftarrow\left(\mathcal{H}_k+\lambda_B I\right)^{-1}\left(\mathcal{b}_k+\lambda_B\,\mathrm{vec}(M_B)\right).
        \]
    \ENDIF

    \STATE For each mode $m$ and expert $k$, compute $N_{m,k}\coloneqq\sum_{t\in\mathcal{T}:I_t=k}\gamma_t^{(m)}$.
    \IF{$N_{m,k} \le \epsilon_N$}
        \STATE Keep $R_{m,k}$ unchanged.
    \ELSE
        \STATE Assume prior $p(R)\propto R^{-(a_R+1)}e^{-b_R/R}$.
        \STATE For $t$ with $I_t=k$, define $\phi_t=\phi(\mathbf{x}_t)$ and
        \[
        \mu_{t,k}^{(m)}\coloneqq \phi_t^\top\left(\mathbf{B}_k\,\mathbb{E}_m[\mathbf{g}_t]+\mathbb{E}_m[\mathbf{u}_{t,k}]\right),
        \qquad
        V_{t,k}^{(m)}\coloneqq \phi_t^\top\left(\mathbf{B}_k\,\mathrm{Cov}_m(\mathbf{g}_t)\,\mathbf{B}_k^\top+\mathrm{Cov}_m(\mathbf{u}_{t,k})\right)\phi_t,
        \]
        \[
        \mathbb{E}_m\!\left[r_{t,k}^2\right]
        \;=\;
        (e_t-\mu_{t,k}^{(m)})^2 + V_{t,k}^{(m)}.
        \]
        \STATE Update
        \[
        R_{m,k}\leftarrow\frac{b_R+\tfrac12\sum_{t\in\mathcal{T}:I_t=k}\gamma_t^{(m)}\,\mathbb{E}_m[r_{t,k}^2]}{a_R+\tfrac12 N_{m,k}+1}.
        \]
    \ENDIF

    \STATE Update transition parameters $\theta$ (attention logits in $\Pi_\theta(\mathbf{x}_t)$) by maximizing
    \[
    \sum_{t\in\mathcal{T}\setminus\{t_a\}}\sum_{\ell,m}\xi_{t-1}^{(\ell,m)}\log \Pi_{\ell\to m}(\mathbf{x}_t)-\frac{\lambda_\theta}{2}\lVert\theta\rVert_2^2
    \]
    with gradient ascent (or any optimizer).
\ENDFOR
\STATE {\bfseries Return:} $\Theta^{(N_\mathrm{EM})}$
\end{algorithmic}
\end{algorithm}

\section{Cross-Covariance in the Exact Update}
\label{app:cross_covariance}

The Kalman update in Algorithm~\ref{alg:correct_reweight} is performed on the joint state
\(\mathbf{s}_t \coloneqq (\mathbf{g}_t,\mathbf{u}_{t,I_t})\). Even if the predictive covariance is
block-diagonal (our factorized predictive belief), the \emph{exact} posterior covariance after
conditioning on the queried residual \(e_t\) generally has non-zero off-diagonal blocks:
\[
\Sigma^{(m)}_{s,t\mid t}
=
\begin{bmatrix}
\Sigma^{(m)}_{g,t\mid t} & \Sigma^{(m)}_{g u,t\mid t} \\
(\Sigma^{(m)}_{g u,t\mid t})^\top & \Sigma^{(m)}_{u,t\mid t}
\end{bmatrix},
\qquad
\Sigma^{(m)}_{g u,t\mid t}\neq \mathbf{0}\ \text{in general}.
\]
These cross terms arise because the observation matrix \(H_t=[\phi(\mathbf{x}_t)^\top\mathbf{B}_{I_t}\;\;\phi(\mathbf{x}_t)^\top]\)
couples \(\mathbf{g}_t\) and \(\mathbf{u}_{t,I_t}\). Retaining \(\Sigma^{(m)}_{g u,t\mid t}\) would
propagate correlation into subsequent steps and into cross-expert predictive covariances.

\paragraph{Closed-form cross-covariance.}
Write the Kalman gain in block form
\(
K_t^{(m)}=\big[(K^{(m)}_{g,t})^\top\ (K^{(m)}_{u,t})^\top\big]^\top
\),
so that the covariance update is
\(
\Sigma^{(m)}_{s,t\mid t}
=
\Sigma^{(m)}_{s,t\mid t-1}
-K_t^{(m)} S^{(m)}_{t,I_t} (K_t^{(m)})^\top
\).
If the predictive covariance is block-diagonal, then the off-diagonal block is
\[
\Sigma^{(m)}_{g u,t\mid t}
=
-K^{(m)}_{g,t} S^{(m)}_{t,I_t} (K^{(m)}_{u,t})^\top
=
-\Sigma^{(m)}_{g,t\mid t-1} H_{g,t}^\top (S^{(m)}_{t,I_t})^{-1} H_{u,t}\Sigma^{(m)}_{u,t\mid t-1},
\]
where \(H_{g,t}=\phi(\mathbf{x}_t)^\top\mathbf{B}_{I_t}\) and \(H_{u,t}=\phi(\mathbf{x}_t)^\top\).
Unless one of these terms is zero, the cross-covariance is non-zero.

\paragraph{Why we discard it.}
Keeping \(\Sigma^{(m)}_{g u,t\mid t}\) is exact but undermines the factorized SLDS approximation that
enables scalable inference under a growing expert registry. Once \(\mathbf{g}_t\) becomes correlated
with \(\mathbf{u}_{t,I_t}\), future prediction steps introduce non-zero cross-covariances between
\(\mathbf{g}_t\) and every \(\mathbf{u}_{t,k}\) that shares dynamics with \(\mathbf{u}_{t,I_t}\), and,
through the shared factor, induce dependence across many experts. This breaks the stored-marginal
structure, increases both compute and memory (scaling with the full registry size), and complicates
closed-form quantities used in Section~\ref{sec:exploration} (e.g., the Gaussian channel form and
information gain). For these reasons, we project back to a factorized belief after each update and
retain only the diagonal blocks as in Algorithm~\ref{alg:correct_reweight}.


% =========================
% Algorithm: OnlineUpdate
% =========================
\begin{algorithm}[H]
\caption{\textsc{OnlineUpdate}: Sliding-Window Monte Carlo EM (non-stationary adaptation)}
\label{alg:online_em}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} current time $t$; stream data $(\mathbf{x}_\tau,\mathcal{E}_\tau,I_\tau,e_\tau)_{\tau\le t}$; current parameters $\Theta^{(t-1)}$; window length $W$; update period $K$; EM iterations $N_{\mathrm{EM}}^{\mathrm{win}}$; posterior samples $N_{\mathrm{samp}}$; burn-in $N_{\mathrm{burn}}$; occupancy floor $\epsilon_N$; priors and $\lambda_\theta$ as in Algorithm~\ref{alg:trainmodel_em}.
\STATE $\tau_0 \leftarrow t-W+1$.
\IF{$t < W$ \textbf{or} $t \bmod K \neq 0$}
    \STATE $\Theta^{(t)} \leftarrow \Theta^{(t-1)}$ and \textbf{return}.
\ENDIF
\STATE Define window $\mathcal{T}_t \leftarrow \{\tau_0,\dots,t\}$ and $\mathcal{K}_t \leftarrow \bigcup_{\tau\in\mathcal{T}_t}\mathcal{E}_\tau$.
\STATE Initialize $(p(z_{\tau_0}),p(g_{\tau_0}\mid z_{\tau_0}),\{p(u_{\tau_0,k}\mid z_{\tau_0})\}_{k\in\mathcal{K}_t})$ from stored filtering beliefs at time $\tau_0-1$ and one time-update; if unavailable, use population priors for $g_{\tau_0}$ and $u_{\tau_0,k}$.
\STATE Run Algorithm~\ref{alg:trainmodel_em} on $\mathcal{T}_t$ with initialization $\Theta^{(t-1)}$, occupancy floor $\epsilon_N$, and $N_{\mathrm{EM}}^{\mathrm{win}}$ iterations.
\STATE Re-run a forward filtering pass over $\mathcal{T}_t$ under $\Theta^{(t)}$ to refresh the belief at time $t$ (starting from the window-initial prior).
\STATE {\bfseries Return:} updated parameters $\Theta^{(t)}$.
\end{algorithmic}
\end{algorithm}

% =========================
% Algorithm: Context-Aware Router
% =========================
\begin{algorithm}[H]
\caption{Context-Aware Router (Factorized SLDS + IMM + IDS)}
\label{alg:router_main}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} horizon $T$; parameters $\Theta$ (or initial window $\mathcal{T}_0=\{1,\dots,t_0\}$ and EM settings for Algorithm~\ref{alg:trainmodel_em}); feature map $\phi$; contexts $(\mathbf{x}_t)_{t=1}^T$; expert sets $(\mathcal{E}_t)_{t=1}^T$; loss $\psi$; fees $(\beta_k)_k$; optional side information for entering experts; optional online EM settings $(W,K,N_{\mathrm{EM}}^{\mathrm{win}},N_{\mathrm{samp}},N_{\mathrm{burn}},\epsilon_N)$; Monte Carlo budget $S$ for information gain estimation (default $S=50$).
\STATE {\bfseries Initialize:} $w_0^m=\mathbb{P}(z_0=m)$; $(\mu^{(m)}_{g,0|0},\Sigma^{(m)}_{g,0|0})$ for $m\in[M]$; $\mathcal{K}^{\text{work}}_0\leftarrow\emptyset$; for all $k$, $\tau_{\mathrm{last}}(k)\leftarrow 0$.
\STATE {\bfseries Hyperparameters:} population priors $(\mu^{(m)}_{\mathrm{pop}},\Sigma^{(m)}_{\mathrm{pop}})_{m=1}^M$; staleness $\Delta_{\max}$; mixing floor $\epsilon_w$; information gain floor $\epsilon_{\mathrm{IG}}$.
\STATE {\bfseries Optional init:} if $\Theta$ is not provided, run Algorithm~\ref{alg:trainmodel_em} on $\mathcal{T}_0$ to obtain $\Theta$.
\STATE {\bfseries Optional init:} if $\mathcal{T}_0$ is used, run a forward filtering pass over $\mathcal{T}_0$ with $\Theta$ to set $(w_{t_0},\{\mu^{(m)}_{g,t_0|t_0},\Sigma^{(m)}_{g,t_0|t_0}\},\{\mu^{(m)}_{u,k,t_0|t_0},\Sigma^{(m)}_{u,k,t_0|t_0}\},\mathcal{K}^{\text{work}}_{t_0},\tau_{\mathrm{last}})$ and set $t_{\mathrm{start}}\leftarrow t_0+1$; else set $t_{\mathrm{start}}\leftarrow 1$.

\FOR{$t=t_{\mathrm{start}}$ to $T$}
    \STATE Observe $(\mathbf{x}_t,\mathcal{E}_t)$.
    \STATE $(\mathcal{K}^{\text{work}}_t,\mathcal{E}^{\mathrm{init}}_t)\leftarrow \textsc{ManageRegistry}(\mathcal{K}^{\text{work}}_{t-1},\mathcal{E}_t,\tau_{\mathrm{last}},\Delta_{\max})$.
    \STATE $\mathcal{K}^{\text{keep}}_t \leftarrow \mathcal{K}^{\text{work}}_t \setminus \mathcal{E}^{\mathrm{init}}_t$.
    \STATE For each $k\in\mathcal{E}^{\mathrm{init}}_t$, set entering priors $(\mu^{(m)}_{\mathrm{init},k},\Sigma^{(m)}_{\mathrm{init},k})_{m=1}^M$ from side information; default to $(\mu^{(m)}_{\mathrm{pop}},\Sigma^{(m)}_{\mathrm{pop}})$. (Assume $\mathbf{B}_k$ is available at entry; otherwise initialize $\mathbf{B}_k$ from metadata / a population prior.)

    \STATE $(\bar w_t,\{\bar\mu^{(m)}_{g,t-1},\bar\Sigma^{(m)}_{g,t-1}\}_{m=1}^M,\{\bar\mu^{(m)}_{u,k,t-1},\bar\Sigma^{(m)}_{u,k,t-1}\}_{m\in[M],\,k\in\mathcal{K}^{\text{keep}}_t})$
    \STATE \hspace{1.9em}$\leftarrow \textsc{IMM}(\mathbf{x}_t,w_{t-1},\{\mu^{(m)}_{g,t-1|t-1},\Sigma^{(m)}_{g,t-1|t-1}\},\{\mu^{(m)}_{u,k,t-1|t-1},\Sigma^{(m)}_{u,k,t-1|t-1}\}_{k\in\mathcal{K}^{\text{keep}}_t},\epsilon_w)$.

    \STATE $(\{\mu^{(m)}_{g,t|t-1},\Sigma^{(m)}_{g,t|t-1}\}_{m=1}^M,\{\mu^{(m)}_{u,k,t|t-1},\Sigma^{(m)}_{u,k,t|t-1}\}_{m\in[M],\,k\in\mathcal{K}^{\text{work}}_t},\{\bar{C}_{t,k}^{\mathrm{pred},(m)}\}_{m\in[M],\,k\in\mathcal{E}_t})$
    \STATE \hspace{1.9em}$\leftarrow \textsc{PredictAndScore}(\mathbf{x}_t,\mathcal{E}_t,\mathcal{K}^{\text{work}}_t,\mathcal{E}^{\mathrm{init}}_t,\{(\mu^{(m)}_{\mathrm{init},k},\Sigma^{(m)}_{\mathrm{init},k})\}_{k\in\mathcal{E}^{\mathrm{init}}_t},\{\bar\mu,\bar\Sigma\},\{(\mu^{(m)}_{\mathrm{pop}},\Sigma^{(m)}_{\mathrm{pop}})\}_{m=1}^M,\Theta,\psi,\beta)$.

    \FOR{each $k\in\mathcal{E}_t$}
        \STATE $\bar{C}_{t,k}^{\mathrm{pred}} \leftarrow \sum_{m=1}^M \bar w_t^{(m)}\,\bar{C}_{t,k}^{\mathrm{pred},(m)}$.
    \ENDFOR
    \STATE $k_t^{\mathrm{pred}} \in \arg\min_{k\in\mathcal{E}_t}\bar{C}_{t,k}^{\mathrm{pred}}$.
    \FOR{each $k\in\mathcal{E}_t$}
        \STATE $\Delta_t(k)\leftarrow \bar{C}_{t,k}^{\mathrm{pred}} - \bar{C}_{t,k_t^{\mathrm{pred}}}^{\mathrm{pred}}$.
    \ENDFOR

    \STATE \COMMENT{Compute full $(z_t,\mathbf{g}_t)$-information gain: $\mathrm{IG}^{(z,g)}_t(k)=\mathcal{I}(z_t;e\mid\mathcal{F}_t)+\mathcal{I}(\mathbf{g}_t;e\mid z_t,\mathcal{F}_t)$}
    \FOR{each $k\in\mathcal{E}_t$}
        \STATE $h_{t,k}\leftarrow \mathbf{B}_k^\top\phi(\mathbf{x}_t)$. \COMMENT{Projection of context onto global factor loading}
        \FOR{$m=1$ to $M$}
            \STATE $s^{(m)}_{t,k} \leftarrow \phi(\mathbf{x}_t)^\top \Sigma^{(m)}_{u,k,t\mid t-1}\phi(\mathbf{x}_t) + R_{m,k}$. \COMMENT{Idiosyncratic + noise variance}
            \STATE $\mu^{(m)}_{e,t,k}\leftarrow h_{t,k}^\top\mu^{(m)}_{g,t|t-1}+\phi(\mathbf{x}_t)^\top\mu^{(m)}_{u,k,t|t-1}$. \COMMENT{Per-mode predictive mean}
            \STATE $v^{(m)}_{e,t,k}\leftarrow h_{t,k}^\top\Sigma^{(m)}_{g,t|t-1}h_{t,k}+s^{(m)}_{t,k}$. \COMMENT{Per-mode predictive variance}
        \ENDFOR
        \STATE \COMMENT{Term 1: Mode-identification $\mathcal{I}(z_t;e_{t,k}^{\mathrm{pred}}\mid\mathcal{F}_t)$ via Monte Carlo}
        \STATE $\widehat{\mathcal{I}}^{(z)}_t(k)\leftarrow 0$.
        \FOR{$m=1$ to $M$}
            \FOR{$s=1$ to $S$}
                \STATE Sample $E_{m,s}\sim\mathcal{N}(\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k})$.
                \STATE $\log p_m\leftarrow -\frac12\log(2\pi v^{(m)}_{e,t,k})-\frac{(E_{m,s}-\mu^{(m)}_{e,t,k})^2}{2v^{(m)}_{e,t,k}}$.
                \STATE $\log p_{\mathrm{mix}}\leftarrow \mathrm{LogSumExp}_{j\in[M]}\!\left(\log\bar{w}_t^{(j)}-\frac12\log(2\pi v^{(j)}_{e,t,k})-\frac{(E_{m,s}-\mu^{(j)}_{e,t,k})^2}{2v^{(j)}_{e,t,k}}\right)$.
                \STATE $\widehat{\mathcal{I}}^{(z)}_t(k)\leftarrow \widehat{\mathcal{I}}^{(z)}_t(k)+\frac{\bar{w}_t^{(m)}}{S}(\log p_m-\log p_{\mathrm{mix}})$.
            \ENDFOR
        \ENDFOR
        \STATE \COMMENT{Term 2: Shared-factor refinement $\mathcal{I}(\mathbf{g}_t;e_{t,k}^{\mathrm{pred}}\mid z_t,\mathcal{F}_t)$ (closed form)}
        \STATE $\mathrm{IG}^{(g)}_t(k)\leftarrow \sum_{m=1}^M \bar{w}_t^{(m)}\,\frac12\log\!\left(1+\frac{h_{t,k}^\top\Sigma^{(m)}_{g,t|t-1}h_{t,k}}{s^{(m)}_{t,k}}\right)$.
        \STATE \COMMENT{Full $(z_t,\mathbf{g}_t)$-information: sum of both terms}
        \STATE $\mathrm{IG}_t(k)\leftarrow \widehat{\mathcal{I}}^{(z)}_t(k)+\mathrm{IG}^{(g)}_t(k)$.
        \STATE $\mathrm{IG}_t(k)\leftarrow \max\!\left(\mathrm{IG}_t(k),\epsilon_{\mathrm{IG}}\right)$. \COMMENT{Clamp negative estimates}
    \ENDFOR
    \STATE {\bfseries Convention:} use the clamped $\mathrm{IG}_t(k)$ in $\Delta_t(k)^2/\mathrm{IG}_t(k)$.
    \STATE Choose $I_t \in \arg\min_{k\in\mathcal{E}_t}\Delta_t(k)^2 / \mathrm{IG}_t(k)$.
    \STATE Observe $(\widehat y_{t,I_t},y_t)$ and set $e_t\leftarrow y_t-\widehat y_{t,I_t}$; $\tau_{\mathrm{last}}(I_t)\leftarrow t$.

    \STATE $(w_t,\{\mu^{(m)}_{g,t|t},\Sigma^{(m)}_{g,t|t}\}_{m=1}^M,\{\mu^{(m)}_{u,k,t|t},\Sigma^{(m)}_{u,k,t|t}\}_{m\in[M],\,k\in\mathcal{K}^{\text{work}}_t})$
    \STATE \hspace{1.9em}$\leftarrow \textsc{Correct}(\mathbf{x}_t,e_t,I_t,\bar w_t,\{\mu^{(m)}_{g,t|t-1},\Sigma^{(m)}_{g,t|t-1}\},\{\mu^{(m)}_{u,k,t|t-1},\Sigma^{(m)}_{u,k,t|t-1}\},\Theta,\mathcal{K}^{\text{work}}_t)$.

    \IF{online adaptation is enabled}
        \STATE $\Theta \leftarrow \textsc{OnlineUpdate}(t,\{(\mathbf{x}_\tau,\mathcal{E}_\tau,I_\tau,e_\tau)\}_{\tau\le t},\Theta,W,K,N_{\mathrm{EM}}^{\mathrm{win}},N_{\mathrm{samp}},N_{\mathrm{burn}},\epsilon_N)$.
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{remark}[$(z_t,\mathbf{g}_t)$-Information Gain for Non-Stationary Routing]
\label{rmk:zg_information}
Algorithm~\ref{alg:router_main} uses the \emph{full} $(z_t,\mathbf{g}_t)$-information gain rather than
conditioning only on $\mathbf{g}_t$. By the chain rule for mutual information:
\begin{equation}
\label{eq:ig_chain_rule_rmk}
\mathcal{I}\!\left((z_t,\mathbf{g}_t);e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)
=
\underbrace{\mathcal{I}\!\left(z_t;e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)}_{\text{mode-identification}}
+
\underbrace{\mathcal{I}\!\left(\mathbf{g}_t;e_{t,k}^{\mathrm{pred}}\,\middle|\,z_t,\mathcal{F}_t\right)}_{\text{shared-factor refinement}}.
\end{equation}
The first term measures how much observing the residual $e_{t,k}^{\mathrm{pred}}$ helps identify the current
regime $z_t$. This is crucial for non-stationarity: when modes have distinct predictive distributions, querying
an expert whose residual discriminates between regimes accelerates adaptation to regime changes.

\textbf{Why both terms matter:}
\begin{itemize}
\item \emph{Shared-factor refinement} (closed-form): Reduces posterior uncertainty about $\mathbf{g}_t$,
improving predictions for \emph{all} experts via Proposition~\ref{prop:cross_update}.
\item \emph{Mode-identification} (Monte Carlo): Reduces uncertainty about $z_t$, ensuring the router uses
the correct dynamics parameters $(A_m^{(g)},Q_m^{(g)},A_m^{(u)},Q_m^{(u)},R_{m,k})$.
\end{itemize}

\textbf{Computational note:} The mode-identification term requires Monte Carlo estimation because the
predictive distribution $p(e_{t,k}\mid\mathcal{F}_t)$ is a Gaussian mixture, for which KL divergence has no
closed form. The LogSumExp trick ensures numerical stability. With $S=50$ samples per expert, the overhead
is negligible compared to the SLDS update cost.
\end{remark}

% =========================
% Algorithm: IMM
% =========================
\begin{algorithm}[H]
\caption{\textsc{IMM}: Context-Dependent IMM Mixing (Moment Matching)}
\label{alg:imm_interact}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} context $\mathbf{x}_t$; mode weights $w_{t-1}$; global posteriors $(\mu^{(i)}_{g,t-1|t-1},\Sigma^{(i)}_{g,t-1|t-1})$; idiosyncratic posteriors $(\mu^{(i)}_{u,k,t-1|t-1},\Sigma^{(i)}_{u,k,t-1|t-1})$ for $k\in\mathcal{K}^{\text{keep}}_t$; mixing floor $\epsilon_w>0$.
\STATE Compute $\Pi_{i\to j}(\mathbf{x}_t)=\mathrm{softmax}_j(S_{ij}(\mathbf{x}_t))$ for all $i,j\in[M]$.
\STATE Unfloored predicted weights: $\tilde w_t^j \leftarrow \sum_{i=1}^M \Pi_{i\to j}(\mathbf{x}_t)\, w_{t-1}^i$ for $j\in[M]$.
\STATE Apply floor and renormalize: $\bar w_t^j \leftarrow \max(\tilde w_t^j,\epsilon_w)$, then $\bar w_t \leftarrow \bar w_t / \sum_{j=1}^M \bar w_t^j$.
\FOR{$j=1$ to $M$}
    \IF{$\tilde w_t^j = 0$}
        \STATE \COMMENT{\textbf{Numerical safety:} Mode $j$ has (near-)zero probability before flooring.}
        \STATE \COMMENT{After flooring, $\bar{w}_t^j\approx\epsilon_w$, so this mode's contribution is negligible.}
        \STATE \COMMENT{The fallback $1/M$ provides well-defined mixing weights; actual values are irrelevant.}
        \FOR{$i=1$ to $M$}
            \STATE $\mu_{t-1}^{i|j} \leftarrow 1/M$
        \ENDFOR
    \ELSE
        \FOR{$i=1$ to $M$}
            \STATE $\mu_{t-1}^{i|j} \leftarrow \Pi_{i\to j}(\mathbf{x}_t)\, w_{t-1}^i / \tilde w_t^j$
        \ENDFOR
    \ENDIF
    \STATE $\bar\mu^{(j)}_{g,t-1} \leftarrow \sum_{i=1}^M \mu_{t-1}^{i|j}\mu^{(i)}_{g,t-1|t-1}$.
    \STATE $\bar\Sigma^{(j)}_{g,t-1} \leftarrow \sum_{i=1}^M \mu_{t-1}^{i|j}\!\left(\Sigma^{(i)}_{g,t-1|t-1}+(\mu^{(i)}_{g,t-1|t-1}-\bar\mu^{(j)}_{g,t-1})(\mu^{(i)}_{g,t-1|t-1}-\bar\mu^{(j)}_{g,t-1})^\top\right)$.
    \FOR{each $k\in\mathcal{K}^{\text{keep}}_t$}
        \STATE $\bar\mu^{(j)}_{u,k,t-1} \leftarrow \sum_{i=1}^M \mu_{t-1}^{i|j}\mu^{(i)}_{u,k,t-1|t-1}$.
        \STATE $\bar\Sigma^{(j)}_{u,k,t-1} \leftarrow \sum_{i=1}^M \mu_{t-1}^{i|j}\!\left(\Sigma^{(i)}_{u,k,t-1|t-1}+(\mu^{(i)}_{u,k,t-1|t-1}-\bar\mu^{(j)}_{u,k,t-1})(\mu^{(i)}_{u,k,t-1|t-1}-\bar\mu^{(j)}_{u,k,t-1})^\top\right)$.
    \ENDFOR
\ENDFOR
\STATE {\bfseries Return:} $(\bar w_t,\{\bar\mu^{(m)}_{g,t-1},\bar\Sigma^{(m)}_{g,t-1}\}_{m=1}^M,\{\bar\mu^{(m)}_{u,k,t-1},\bar\Sigma^{(m)}_{u,k,t-1}\}_{m\in[M],\,k\in\mathcal{K}^{\text{keep}}_t})$.
\end{algorithmic}
\end{algorithm}

% =========================
% Algorithm: PredictAndScore
% =========================
\begin{algorithm}[H]
\caption{\textsc{PredictAndScore}: Mode-Wise Prediction and Myopic Costing}
\label{alg:predict_score}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} $\mathbf{x}_t$, $\mathcal{E}_t$, $\mathcal{K}^{\text{work}}_t$, $\mathcal{E}^{\mathrm{init}}_t$, entering priors $\{(\mu^{(m)}_{\mathrm{init},k},\Sigma^{(m)}_{\mathrm{init},k})\}_{k\in\mathcal{E}^{\mathrm{init}}_t}$; mixed states $\{(\bar\mu^{(m)}_{g,t-1},\bar\Sigma^{(m)}_{g,t-1})\}_{m=1}^M$ and $\{(\bar\mu^{(m)}_{u,k,t-1},\bar\Sigma^{(m)}_{u,k,t-1})\}_{m\in[M],\,k\in\mathcal{K}^{\text{keep}}_t}$; population priors $(\mu^{(m)}_{\mathrm{pop}},\Sigma^{(m)}_{\mathrm{pop}})_{m=1}^M$; parameters $\Theta$; loss $\psi$; fees $\beta$.
\STATE $\mathcal{K}^{\text{keep}}_t \leftarrow \mathcal{K}^{\text{work}}_t \setminus \mathcal{E}^{\mathrm{init}}_t$.
\FOR{$m=1$ to $M$}
    \STATE $\mu^{(m)}_{g,t|t-1}\leftarrow A_m^{(g)}\bar\mu^{(m)}_{g,t-1}$,\;
    $\Sigma^{(m)}_{g,t|t-1}\leftarrow A_m^{(g)}\bar\Sigma^{(m)}_{g,t-1}(A_m^{(g)})^\top+Q_m^{(g)}$.
    \FOR{each $k\in\mathcal{K}^{\text{keep}}_t$}
        \STATE $\mu^{(m)}_{u,k,t|t-1}\leftarrow A_m^{(u)}\bar\mu^{(m)}_{u,k,t-1}$,\;
        $\Sigma^{(m)}_{u,k,t|t-1}\leftarrow A_m^{(u)}\bar\Sigma^{(m)}_{u,k,t-1}(A_m^{(u)})^\top+Q_m^{(u)}$.
    \ENDFOR
    \FOR{each $k\in\mathcal{E}^{\mathrm{init}}_t$}
        \STATE $\mu^{(m)}_{u,k,t|t-1}\leftarrow \mu^{(m)}_{\mathrm{init},k}$,\;
        $\Sigma^{(m)}_{u,k,t|t-1}\leftarrow \Sigma^{(m)}_{\mathrm{init},k}$.
    \ENDFOR
    \FOR{each $k\in\mathcal{E}_t$}
        \STATE $\bar e_{t,k}^{\mathrm{pred},(m)} \leftarrow \phi(\mathbf{x}_t)^\top(\mathbf{B}_k\mu^{(m)}_{g,t|t-1}+\mu^{(m)}_{u,k,t|t-1})$.
        \STATE $S_{t,k}^{\mathrm{pred},(m)} \leftarrow \phi(\mathbf{x}_t)^\top(\mathbf{B}_k\Sigma^{(m)}_{g,t|t-1}\mathbf{B}_k^\top+\Sigma^{(m)}_{u,k,t|t-1})\phi(\mathbf{x}_t)+R_{m,k}$.
        \STATE $\bar{C}_{t,k}^{\mathrm{pred},(m)}\leftarrow \mathbb{E}_{e\sim\mathcal{N}(\bar e_{t,k}^{\mathrm{pred},(m)},S_{t,k}^{\mathrm{pred},(m)})}[\psi(e)]+\beta_k$.
        \COMMENT{closed form for common $\psi$; else approximate numerically}
    \ENDFOR
\ENDFOR
\STATE {\bfseries Return:} $\{\mu^{(m)}_{g,t|t-1},\Sigma^{(m)}_{g,t|t-1}\}$, $\{\mu^{(m)}_{u,k,t|t-1},\Sigma^{(m)}_{u,k,t|t-1}\}$, and $\{\bar{C}_{t,k}^{\mathrm{pred},(m)}\}_{m\in[M],\,k\in\mathcal{E}_t}$.
\end{algorithmic}
\end{algorithm}

% =========================
% Algorithm: Correct
% =========================
\begin{algorithm}[H]
\caption{\textsc{Correct}: Queried Kalman Update and Mode Posterior}
\label{alg:correct_reweight}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} $\mathbf{x}_t$, queried residual $e_t$, queried expert $I_t$; predicted weights $\bar w_t$; predicted states $\{\mu^{(m)}_{g,t|t-1},\Sigma^{(m)}_{g,t|t-1}\}$ and $\{\mu^{(m)}_{u,k,t|t-1},\Sigma^{(m)}_{u,k,t|t-1}\}$; parameters (including $\mathbf{B}_{I_t},R_{m,I_t}$); registry $\mathcal{K}^{\text{work}}_t$.
\FOR{$m=1$ to $M$}
    \STATE $H_t \leftarrow [\phi(\mathbf{x}_t)^\top \mathbf{B}_{I_t}\;\;\phi(\mathbf{x}_t)^\top]$.
    \STATE $\mu^{(m)}_{s,t|t-1} \leftarrow [(\mu^{(m)}_{g,t|t-1})^\top\;(\mu^{(m)}_{u,I_t,t|t-1})^\top]^\top$.
    \STATE $\Sigma^{(m)}_{s,t|t-1} \leftarrow \mathrm{diag}(\Sigma^{(m)}_{g,t|t-1},\Sigma^{(m)}_{u,I_t,t|t-1})$.
    \STATE $\bar e_{t,I_t}^{\mathrm{pred},(m)} \leftarrow H_t\mu^{(m)}_{s,t|t-1}$,\;
    $S_{t,I_t}^{\mathrm{pred},(m)} \leftarrow H_t\Sigma^{(m)}_{s,t|t-1}H_t^\top + R_{m,I_t}$.
    \STATE $K_t^{(m)} \leftarrow \Sigma^{(m)}_{s,t|t-1}H_t^\top(S_{t,I_t}^{\mathrm{pred},(m)})^{-1}$.
    \STATE $\mu^{(m)}_{s,t|t} \leftarrow \mu^{(m)}_{s,t|t-1} + K_t^{(m)}(e_t-\bar e_{t,I_t}^{\mathrm{pred},(m)})$.
    \STATE $\Sigma^{(m)}_{s,t|t} \leftarrow \Sigma^{(m)}_{s,t|t-1} - K_t^{(m)}S_{t,I_t}^{\mathrm{pred},(m)}(K_t^{(m)})^\top$.
    \STATE \COMMENT{\textbf{Factorized projection:} $\Sigma^{(m)}_{s,t|t}$ has non-zero off-diagonal blocks (induced $\mathbf{g}_t$--$\mathbf{u}_{t,I_t}$ correlation).}
    \STATE \COMMENT{We extract only the diagonal blocks, discarding cross-covariance to maintain factorization; see Appendix~\ref{app:cross_covariance}.}
    \STATE Extract $(\mu^{(m)}_{g,t|t},\Sigma^{(m)}_{g,t|t})$ and $(\mu^{(m)}_{u,I_t,t|t},\Sigma^{(m)}_{u,I_t,t|t})$ from diagonal blocks of $(\mu^{(m)}_{s,t|t},\Sigma^{(m)}_{s,t|t})$.
    \FOR{each $k\in\mathcal{K}^{\text{work}}_t\setminus\{I_t\}$}
        \STATE $(\mu^{(m)}_{u,k,t|t},\Sigma^{(m)}_{u,k,t|t}) \leftarrow (\mu^{(m)}_{u,k,t|t-1},\Sigma^{(m)}_{u,k,t|t-1})$.
    \ENDFOR
    \STATE $\mathcal{L}_t^{(m)} \leftarrow \mathcal{N}\!\big(e_t \mid \bar e_{t,I_t}^{\mathrm{pred},(m)},S_{t,I_t}^{\mathrm{pred},(m)}\big)$.
\ENDFOR
\STATE Updated weights: $w_t^m \leftarrow \frac{\mathcal{L}_t^{(m)}\bar w_t^m}{\sum_{\ell=1}^M \mathcal{L}_t^{(\ell)}\bar w_t^\ell}$.
\STATE {\bfseries Return:} $w_t$ and updated posteriors $\{\mu^{(m)}_{g,t|t},\Sigma^{(m)}_{g,t|t}\}$, $\{\mu^{(m)}_{u,k,t|t},\Sigma^{(m)}_{u,k,t|t}\}$.
\end{algorithmic}
\end{algorithm}

% =========================
% Algorithm: ManageRegistry
% =========================
\begin{algorithm}[H]
\caption{\textsc{ManageRegistry}: Entering/Stale Experts}
\label{alg:registry}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} $\mathcal{K}^{\text{work}}_{t-1}$, $\mathcal{E}_t$, $\tau_{\mathrm{last}}(\cdot)$, $\Delta_{\max}$.
\STATE $\mathcal{E}^{\mathrm{init}}_t \leftarrow \mathcal{E}_t \setminus \mathcal{K}^{\text{work}}_{t-1}$.
\STATE $\mathcal{K}^{\mathrm{stale}}_t \leftarrow \{k\in\mathcal{K}^{\text{work}}_{t-1}\setminus\mathcal{E}_t:\ t-\tau_{\mathrm{last}}(k)>\Delta_{\max}\}$.
\STATE $\mathcal{K}^{\text{work}}_t \leftarrow (\mathcal{K}^{\text{work}}_{t-1}\setminus\mathcal{K}^{\mathrm{stale}}_t)\cup \mathcal{E}^{\mathrm{init}}_t$.
\STATE {\bfseries Side effect:} for $k\in\mathcal{K}^{\mathrm{stale}}_t$, delete stored idiosyncratic marginals for $u_{\cdot,k}$ (exact marginalization of dropped coordinates).
\STATE {\bfseries Return:} $\mathcal{K}^{\text{work}}_t$, $\mathcal{E}^{\mathrm{init}}_t$.
\end{algorithmic}
\end{algorithm}

% =========================
% Predictive Scheduling Details
% =========================
\section{Predictive Scheduling with Relative-Thresholded Sets}
\label{app:planning_relative_threshold}

We collect the scheduling notation and the relative-threshold rule used in the experiments.
At decision time $t$, the planner has access to the working registry $\mathcal{K}^{\text{work}}_t$ and
feasibility constraints $\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}=\mathcal{K}^{\text{work}}_t\cap\mathcal{A}_{t+h}$.
Given a forecast trajectory $\mathbf{x}_{t+1:t+H}$, the open-loop planner selects
\begin{equation}
I_{t+h}^{\ast}(\mathbf{x}_{t+1:t+h})
\in
\arg\min_{k\in\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}} C_{t+h,k}^{\dagger}(\mathbf{x}_{t+1:t+h}),
\qquad h=1,\dots,H,
\end{equation}
where $C_{t+h,k}^{\dagger}$ is the predicted cost obtained by propagating the time-$t$ belief without
any measurement updates. This defines the random planned winner $I_{t+h}^{\ast}$ under the
scenario distribution $p(\mathbf{X}_{t+1:t+H}\mid\mathcal{F}_t)$ and yields the time-marginal demand
\begin{equation}
\rho_{t,h}(k)\coloneqq \mathbb{P}\!\left(I_{t+h}^{\ast}=k\mid\mathcal{F}_t\right),\qquad
k\in\mathcal{K}^{\text{work}}_t.
\end{equation}

We summarize the demand with a relative-thresholded active set. Let
\(
\rho^{\max}_{t,h}\coloneqq \max_{k\in\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}}\rho_{t,h}(k)
\)
(with $\rho^{\max}_{t,h}=0$ when the feasible set is empty). For $\delta\in[0,1)$, define
\begin{equation}
\mathcal{S}_{t,h}(\delta)
\coloneqq
\left\{k\in\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}:\rho_{t,h}(k)\ge (1-\delta)\rho^{\max}_{t,h}\right\}.
\end{equation}
This rule keeps the on-call experts whose probability is within a multiplicative gap of the most
likely expert. It is scale-free, does not depend on the number of experts, and is never empty when
$\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}\neq\varnothing$. The extremes are
$\delta=0$ (only maximizers) and $\delta\uparrow 1$ (all feasible experts). The mapping is monotone:
if $0\le \delta_1\le \delta_2<1$ then $\mathcal{S}_{t,h}(\delta_1)\subseteq\mathcal{S}_{t,h}(\delta_2)$.

\paragraph{Monte Carlo plug-in estimator.}
With $N$ sampled scenarios, we estimate $\rho_{t,h}(k)$ by
\(
\hat{\rho}_{t,h}(k)=\frac{1}{N}\sum_{n=1}^N\mathbf{1}\{\widehat{I}^{(n)}_{t+h}=k\}
\)
and define the plug-in max
\(
\hat{\rho}^{\max}_{t,h}=\max_{k\in\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}}\hat{\rho}_{t,h}(k)
\).
The estimated active set is
\begin{equation}
\widehat{\mathcal{S}}_{t,h}(\delta)
\coloneqq
\left\{k\in\mathcal{E}^{\mathrm{feas}}_{t+h\mid t}:\hat{\rho}_{t,h}(k)\ge (1-\delta)\hat{\rho}^{\max}_{t,h}\right\}.
\end{equation}
The resulting trajectory $\widehat{\mathcal{S}}_{t:t+H}(\delta)$ is the on-call plan reported by the
planner.


% \section{Time Complexity Analysis}

% Our router operates in real time with per-round cost linear in the number of active experts. Let $M$ denote the number of latent regimes, $d_g$ and $d_\alpha$ the dimensions of the global and idiosyncratic latent states, and $|{\mathcal{K}}_t|$ the size of the working expert registry at time $t$. Assuming $d_g, d_\alpha = O(1)$, the computational cost of each step in Algorithm~\ref{alg:router_main} is:

% \begin{itemize}
%     \item \textbf{Registry management (Alg.~\ref{alg:registry})}: $O(|{\mathcal{K}}_t|)$ for pruning and birth.
%     \item \textbf{IMM mixing (Alg.~\ref{alg:imm_interact})}: $O(M^2 |{\mathcal{K}}_t|)$ to compute mixing weights and moment-matched priors.
%     \item \textbf{Predict and score (Alg.~\ref{alg:predict_score})}: $O(M \max\{|\mathcal{E}_t|,|{\mathcal{K}}_t|\})$ to evaluate predictive costs for available experts.
%     \item \textbf{Correct (Alg.~\ref{alg:correct_reweight})}: $O(M|{\mathcal{K}}_t|)$ for Kalman update (only the selected expert $I_t$ is corrected).
% \end{itemize}

% Summing these, the total per-round complexity is $O(M^2 |{\mathcal{K}}_t|)$. In practice, with a fixed number of regimes ($M = O(1)$), this simplifies to $O(|{\mathcal{K}}_t|)$, which is linear in the working registry size.

\section{Proof of Proposition \ref{prop:cross_update}}
\label{app:proof_cross_update}

\propinfo*

\begin{proof}
Fix $t$ and $m$, and let $\mathcal{G}_t \coloneqq \sigma(\mathcal{F}_t, I_t, z_t=m)$.
By assumption, the one-step-ahead predictive vector
$(e_{t,j}^{\mathrm{pred}}, e_{t,I_t}^{\mathrm{pred}}) \mid \mathcal{G}_t$ is jointly Gaussian.
Let
\[
\mu_j \coloneqq \mathbb{E}[e_{t,j}^{\mathrm{pred}}\mid \mathcal{G}_t], \qquad
\mu_I \coloneqq \mathbb{E}[e_{t,I_t}^{\mathrm{pred}}\mid \mathcal{G}_t],
\]
and define the predictive variance and cross-covariance
\[
\sigma_I^2 \coloneqq \mathrm{Var}(e_{t,I_t}^{\mathrm{pred}}\mid \mathcal{G}_t), \qquad
\sigma_{jI} \coloneqq \mathrm{Cov}(e_{t,j}^{\mathrm{pred}}, e_{t,I_t}^{\mathrm{pred}}\mid \mathcal{G}_t).
\]
Assume $\sigma_I^2>0$ (e.g., due to additive observation noise).
For jointly Gaussian variables, the conditional expectation is given by the standard formula
\[
\mathbb{E}[e_{t,j}^{\mathrm{pred}}\mid e_t, \mathcal{G}_t]
=
\mu_j + \sigma_{jI}\,\sigma_I^{-2}\,\bigl(e_t-\mu_I\bigr).
\]
Therefore,
$\mathbb{E}[e_{t,j}^{\mathrm{pred}}\mid e_t, \mathcal{G}_t]=\mu_j$ for all values of $e_t$
if and only if $\sigma_{jI}=0$, i.e.,
$\mathrm{Cov}(e_{t,j}^{\mathrm{pred}}, e_{t,I_t}^{\mathrm{pred}}\mid \mathcal{F}_t, I_t, z_t=m)=0$.
\end{proof}

\section{Proof of Proposition \ref{prop:invariance}} \label{app:invariance}

\invariance*

\begin{proof}
The statement is a direct consequence of the definition of marginalization.

Write the filtering belief at the end of round $t-1$ (conditioned on the realized history, which we omit from the
notation) as a joint density over the shared factor and all idiosyncratic states:
\[
q_{t-1\mid t-1}\Big(\mathbf g_{t-1},(\mathbf u_{t-1,\ell})_{\ell\in\mathcal K^{\text{work}}_{t-1}}\Big).
\]
Let $\mathcal K' \coloneqq \mathcal K^{\text{work}}_{t-1}\setminus P_t$ denote the retained experts and denote
$\mathbf u_{t-1,\mathcal K'} \coloneqq (\mathbf u_{t-1,\ell})_{\ell\in\mathcal K'}$.
By the definition of a marginal density, the joint marginal of the retained variables under $q_{t-1\mid t-1}$ is
\begin{equation}
q_{t-1\mid t-1}\big(\mathbf g_{t-1},\mathbf u_{t-1,\mathcal K'}\big)
\;=\;
\int q_{t-1\mid t-1}\big(\mathbf g_{t-1},\mathbf u_{t-1,\mathcal K'},(\mathbf u_{t-1,k})_{k\in P_t}\big)\,
\prod_{k\in P_t} d\mathbf u_{t-1,k}.
\label{eq:marg_def}
\end{equation}
On the other hand, the post-pruning belief $q^{\mathrm{pr}(P_t)}_{t-1\mid t-1}$ is \emph{defined} by exactly the same integral:
\[
q^{\mathrm{pr}(P_t)}_{t-1\mid t-1}\big(\mathbf g_{t-1},\mathbf u_{t-1,\mathcal K'}\big)
\;\coloneqq\;
\int q_{t-1\mid t-1}\big(\mathbf g_{t-1},\mathbf u_{t-1,\mathcal K'},(\mathbf u_{t-1,k})_{k\in P_t}\big)\,
\prod_{k\in P_t} d\mathbf u_{t-1,k}.
\]
Comparing with \eqref{eq:marg_def} yields
\[
q^{\mathrm{pr}(P_t)}_{t-1\mid t-1}\big(\mathbf g_{t-1},\mathbf u_{t-1,\mathcal K'}\big)
=
q_{t-1\mid t-1}\big(\mathbf g_{t-1},\mathbf u_{t-1,\mathcal K'}\big),
\]
which proves that pruning $P_t$ leaves the joint belief over all retained variables unchanged.

For the stated consequences, let $\ell\notin P_t$.
The SLDS time update propagates $(\mathbf g_{t-1},\mathbf u_{t-1,\ell})$ to $(\mathbf g_t,\mathbf u_{t,\ell})$
using the same linear-Gaussian transition under both beliefs. Since the retained marginal
$q_{t-1\mid t-1}(\mathbf g_{t-1},\mathbf u_{t-1,\ell})$ is identical before and after pruning, the predictive
distribution of $(\mathbf g_t,\mathbf u_{t,\ell})$ is also identical. Because
$\boldsymbol{\alpha}_{t,\ell}=\mathbf B_\ell \mathbf g_t+\mathbf u_{t,\ell}$ is a measurable function of
$(\mathbf g_t,\mathbf u_{t,\ell})$ and $e_{t,\ell}^{\mathrm{pred}}$ follows the emission model given these
states, the predictive distributions of $\boldsymbol{\alpha}_{t,\ell}$ and $e_{t,\ell}^{\mathrm{pred}}$
are unchanged by pruning.
\end{proof}

\section{Proof of Proposition \ref{prop:transfer}} \label{app:transfer}

\transfer*

\begin{proof}
Fix $t$ and condition on $(\mathcal F_t,z_t=m)$.
Under the factorized one-step predictive belief,
\[
q(\mathbf g_t,(\mathbf u_{t,\ell})_\ell \mid \mathcal F_t,z_t=m)
=
q(\mathbf g_t\mid \mathcal F_t,z_t=m)\prod_{\ell} q(\mathbf u_{t,\ell}\mid \mathcal F_t,z_t=m),
\]
so $\mathbf g_t \perp\!\!\!\perp \mathbf u_{t,\ell}$ for all $\ell$ and
$\mathbf u_{t,j}\perp\!\!\!\perp \mathbf u_{t,k}$ for $j\neq k$.
Recalling $\boldsymbol\alpha_{t,\ell}=\mathbf B_\ell \mathbf g_t+\mathbf u_{t,\ell}$ and using bilinearity of covariance,
\begin{align*}
\mathrm{Cov}(\boldsymbol\alpha_{t,j},\boldsymbol\alpha_{t,k}\mid \mathcal F_t,z_t=m)
&=\mathrm{Cov}(\mathbf B_j\mathbf g_t+\mathbf u_{t,j},\,\mathbf B_k\mathbf g_t+\mathbf u_{t,k}\mid \mathcal F_t,z_t=m)\\
&=\mathrm{Cov}(\mathbf B_j\mathbf g_t,\,\mathbf B_k\mathbf g_t\mid \mathcal F_t,z_t=m)
+\mathrm{Cov}(\mathbf B_j\mathbf g_t,\,\mathbf u_{t,k}\mid \mathcal F_t,z_t=m)\\
&\quad+\mathrm{Cov}(\mathbf u_{t,j},\,\mathbf B_k\mathbf g_t\mid \mathcal F_t,z_t=m)
+\mathrm{Cov}(\mathbf u_{t,j},\,\mathbf u_{t,k}\mid \mathcal F_t,z_t=m)\\
&=\mathbf B_j\,\mathrm{Cov}(\mathbf g_t,\mathbf g_t\mid \mathcal F_t,z_t=m)\,\mathbf B_k^\top\\
&=\mathbf B_j\,\Sigma^{(m)}_{g,t|t-1}\,\mathbf B_k^\top,
\end{align*}
where $\Sigma^{(m)}_{g,t|t-1}\coloneqq \mathrm{Cov}(\mathbf g_t\mid \mathcal F_t,z_t=m)$.
If $\mathbf B_j\Sigma^{(m)}_{g,t|t-1}\mathbf B_k^\top\neq 0$ and the joint predictive law of
$(\boldsymbol\alpha_{t,j},\boldsymbol\alpha_{t,k})$ is Gaussian, then they are not independent, hence
$\mathcal I(\boldsymbol\alpha_{t,j};\boldsymbol\alpha_{t,k}\mid \mathcal F_t,z_t=m)>0$.
\end{proof}


% \section{Proof of Dynamic Structural Inference Properties}
% \label{app:proofs}

% In this section, we provide the formal derivation for Proposition~\ref{prop:plasticity}, confirming that our dynamic registry management (pruning and birth) is mathematically consistent with the underlying probabilistic graphical model.

% \propplasticity*

% \subsection{Proof of Part 1: Invariance to Pruning}
% \label{proof:part1}

% \textbf{Objective:} We must demonstrate that removing the idiosyncratic state $\mathbf{u}_{t,k}$ from the joint belief state does not alter the marginal posterior of the global factor $\mathbf{g}_t$, provided that expert $k$ is not observed at time $t$.

% \textbf{Step 1: Factorization of the Joint Prior.}
% Consider the joint predictive distribution at time $t$ given history $\mathcal{H}_{t-1}$. Due to the structural independence defined in the transition dynamics (Section \ref{sec:generative_model}), the joint prior factorizes conditional on the regime $z_t$. For notational simplicity, we omit the conditioning on $z_t=m$ as the result holds for every component of the mixture.
% The joint predictive density is:
% \begin{equation}
%     p(\mathbf{g}_t, \mathbf{u}_{t, 1}, \dots, \mathbf{u}_{t, K} \mid \mathcal{H}_{t-1}) \;=\; p(\mathbf{g}_t \mid \mathcal{H}_{t-1}) \prod_{i \in \mathcal{K}_t} p(\mathbf{u}_{t, i} \mid \mathcal{H}_{t-1}).
% \end{equation}
% Let $\mathbf{S}_t = [\mathbf{g}_t^\top, \mathbf{u}_{t,1}^\top, \dots, \mathbf{u}_{t,K}^\top]^\top$ denote the full latent state vector. The joint covariance matrix $\boldsymbol{\Sigma}_{t|t-1}$ is block-diagonal between the global factor and the idiosyncratic blocks.

% \textbf{Step 2: Bayesian Update under Partial Observation.}
% At time $t$, the router selects expert $I_t$ and observes the residual $r_{t, I_t}$. A "stale" expert $k \in \mathcal{K}^{\text{stale}}_t$ is, by definition, not in the available set $\mathcal{E}_t$, which implies $k \neq I_t$. Thus, $r_{t, I_t}$ depends only on $\mathbf{g}_t$ and $\mathbf{u}_{t, I_t}$.
% The observation model is:
% \begin{equation}
%     r_{t, I_t} = \mathbf{C}_{I_t} \mathbf{S}_t + v_t,
% \end{equation}
% where the observation matrix $\mathbf{C}_{I_t}$ has zero entries for all columns corresponding to $\mathbf{u}_{t, k}$.

% \textbf{Step 3: Analytical Marginalization.}
% We seek the marginal posterior $p(\mathbf{g}_t \mid \mathcal{H}_t)$. Using the definition of the posterior:
% \begin{align}
%     p(\mathbf{g}_t \mid \mathcal{H}_t) &= \int \dots \int p(\mathbf{S}_t \mid r_{t, I_t}) \, d\mathbf{u}_{t, 1} \dots d\mathbf{u}_{t, K} \\
%     &\propto \int \dots \int p(r_{t, I_t} \mid \mathbf{S}_t) p(\mathbf{S}_t \mid \mathcal{H}_{t-1}) \, d\mathbf{u}_{t, 1} \dots d\mathbf{u}_{t, K}.
% \end{align}
% Since the likelihood $p(r_{t, I_t} \mid \mathbf{S}_t)$ is independent of $\mathbf{u}_{t,k}$, we can isolate the integral with respect to $\mathbf{u}_{t,k}$:
% \begin{equation}
%     \int p(\mathbf{u}_{t,k} \mid \mathcal{H}_{t-1}) \, d\mathbf{u}_{t,k} = 1.
% \end{equation}
% The term associated with expert $k$ integrates to unity and vanishes from the equation. Consequently, the posterior update for $\mathbf{g}_t$ depends exclusively on the prior $p(\mathbf{g}_t \mid \mathcal{H}_{t-1})$, the active expert's prior $p(\mathbf{u}_{t,I_t} \mid \mathcal{H}_{t-1})$, and the likelihood. The presence or absence of $\mathbf{u}_{t,k}$ in the registry matrix has zero analytical impact on the posterior of $\mathbf{g}_t$.
% \hfill $\blacksquare$

% \subsection{Proof of Part 2: Non-Trivial Information Transfer}
% \label{proof:part2}

% \textbf{Objective:} We show that the mutual information $I(\boldsymbol{\alpha}_{t,j} ; \boldsymbol{\alpha}_{t, i} \mid \mathcal{H}_{t-1})$ is strictly positive for a new expert $j$ and an existing expert $i$.

% \textbf{Step 1: Representation of Reliability States.}
% Recall the definition of the reliability state for any expert $k$:
% \begin{equation}
%     \boldsymbol{\alpha}_{t,k} = \mathbf{B}_k \mathbf{g}_t + \mathbf{u}_{t,k}.
% \end{equation}
% Conditioned on history $\mathcal{H}_{t-1}$, $\mathbf{g}_t$ and the idiosyncratic noise terms $\mathbf{u}$ are independent Gaussian vectors. Let $\boldsymbol{\Sigma}_{g, t|t-1}$ denote the predictive covariance of the global factor.

% \textbf{Step 2: Cross-Covariance Derivation.}
% We compute the conditional cross-covariance between the new expert $j$ (initialized with a population prior) and an existing expert $i$:
% \begin{align}
%     \mathrm{Cov}(\boldsymbol{\alpha}_{t,j}, \boldsymbol{\alpha}_{t,i} \mid \mathcal{H}_{t-1}) &= \mathbb{E}\left[ (\mathbf{B}_j \tilde{\mathbf{g}}_t + \tilde{\mathbf{u}}_{t,j})(\mathbf{B}_i \tilde{\mathbf{g}}_t + \tilde{\mathbf{u}}_{t,i})^\top \right] \\
%     &= \mathbf{B}_j \mathbb{E}[\tilde{\mathbf{g}}_t \tilde{\mathbf{g}}_t^\top] \mathbf{B}_i^\top + \underbrace{\mathbb{E}[\tilde{\mathbf{u}}_{t,j} \tilde{\mathbf{g}}_t^\top]}_{0} \mathbf{B}_i^\top + \dots \\
%     &= \mathbf{B}_j \boldsymbol{\Sigma}_{g, t|t-1} \mathbf{B}_i^\top.
% \end{align}
% The cross-terms vanish because idiosyncratic states are independent of the global factor and of each other. Assuming non-trivial loading matrices $\mathbf{B}$ and a positive definite global covariance $\boldsymbol{\Sigma}_{g, t|t-1} \succ 0$, this cross-covariance matrix is non-zero.

% \textbf{Step 3: Connection to Mutual Information.}
% For jointly Gaussian variables $X, Y$, the mutual information is strictly positive if and only if they are correlated (i.e., $\mathrm{Cov}(X, Y) \neq \mathbf{0}$).
% Specifically, the mutual information is given by:
% \begin{equation}
%     I(\boldsymbol{\alpha}_{t,j} ; \boldsymbol{\alpha}_{t, i}) = -\frac{1}{2} \ln \left( \frac{|\boldsymbol{\Sigma}_{\alpha_j \alpha_i}|}{|\boldsymbol{\Sigma}_{\alpha_j}| |\boldsymbol{\Sigma}_{\alpha_i}|} \right) > 0.
% \end{equation}
% \textbf{Interpretation:} Expert $j$ is initialized with a generic prior on $\mathbf{u}_{t,j}$, but its effective reliability $\boldsymbol{\alpha}_{t,j}$ includes the term $\mathbf{B}_j \mathbf{g}_t$. Since the posterior of $\mathbf{g}_t$ has been refined by the history of observations from expert $i$, expert $j$ immediately inherits this information structure.
% \hfill $\blacksquare$


--

% Standalone replacement text for the exploration section.
% Intended to be included from main.tex via \input{exploration}.

% Standalone replacement text for the exploration subsection in main.tex.
% Intended to be included via \input{exploration}.

% Standalone replacement text for the exploration subsection in main.tex.
% Intended to be included via \input{exploration}.

\subsubsection{Exploration via \((z_t,\mathbf{g}_t)\)-information}
\label{sec:exploration_zg}

Bandit feedback reveals only the queried expert's residual, so the router must trade off
\emph{exploitation} (low immediate cost) against \emph{learning} (reducing posterior uncertainty to
improve future decisions).
In our IMM-factorized SLDS, two latent objects drive both non-stationarity and cross-expert transfer:
the regime \(z_t\in\{1,\dots,M\}\) and the shared factor \(\mathbf{g}_t\) (Proposition~\ref{prop:cross_update}).
We therefore score exploration by the information gained about the \emph{joint} latent state
\((z_t,\mathbf{g}_t)\) from the (potential) queried residual.
Throughout, logarithms are natural unless stated otherwise, so mutual information is measured in nats
(replace \(\log\) by \(\log_2\) to obtain bits).
We reuse the core SLDS/IMM notation from the main text: \(\phi(\mathbf{x}_t)\), \(\mathbf{B}_k\),
\(\bar{w}_t^{(m)}=\mathbb{P}(z_t=m\mid\mathcal{F}_t)\), and the predictive moments
\((\mu^{(m)}_{g,t\mid t-1},\Sigma^{(m)}_{g,t\mid t-1})\), \((\mu^{(m)}_{u,k,t\mid t-1},\Sigma^{(m)}_{u,k,t\mid t-1})\), and \(R_{m,k}\).
For Monte Carlo, we use \(\tilde{\cdot}\) to denote sampled quantities and write
\(\tilde z\sim \mathrm{Cat}((\bar{w}_t^{(m)})_{m=1}^M)\) for a categorical draw from the mode weights.

\paragraph{Decision-time predictive random variables.}
At round \(t\), the decision-time sigma-algebra is
\(
\mathcal{F}_t=\sigma(\mathcal{H}_{t-1},\mathbf{x}_t,\mathcal{E}_t)
\)
and the router chooses \(I_t\in\mathcal{E}_t\).
For each available expert \(k\in\mathcal{E}_t\), define the pre-query predictive residual random variable
\begin{equation}
\label{eq:exp_pred_rv}
e_{t,k}^{\mathrm{pred}} \sim p(e_{t,k}\mid \mathcal{F}_t).
\end{equation}
If \(I_t=k\), the realized observation is \(e_t=e_{t,k}\) and
\(
e_t \mid (\mathcal{F}_t,I_t=k)\overset{d}{=} e_{t,k}^{\mathrm{pred}}\mid \mathcal{F}_t.
\)

\paragraph{Per-mode linear-Gaussian predictive parametrization (IMM outputs).}
Fix a regime \(z_t=m\).
The IMM predictive step yields a Gaussian predictive prior for the shared factor:
\begin{equation}
\label{eq:exp_g_prior}
\mathbf{g}_t\mid(\mathcal{F}_t,z_t=m)\sim
\mathcal{N}\!\left(\mu^{(m)}_{g,t\mid t-1},\,\Sigma^{(m)}_{g,t\mid t-1}\right).
\end{equation}
Under the factorized predictive belief, querying expert \(k\) induces the linear-Gaussian observation channel
\begin{equation}
\label{eq:exp_channel}
e_{t,k}^{\mathrm{pred}} \mid (\mathbf{g}_t,\mathcal{F}_t,z_t=m)
\sim
\mathcal{N}\!\big(h_{t,k}^\top \mathbf{g}_t + b^{(m)}_{t,k},\, s^{(m)}_{t,k}\big),
\end{equation}
with mode-specific quantities
\begin{equation}
\label{eq:exp_channel_params}
h_{t,k}\coloneqq \mathbf{B}_k^\top \phi(\mathbf{x}_t)\in\mathbb{R}^{d_g},
\qquad
b^{(m)}_{t,k}\coloneqq \phi(\mathbf{x}_t)^\top \mu^{(m)}_{u,k,t\mid t-1},
\qquad
s^{(m)}_{t,k}\coloneqq
\phi(\mathbf{x}_t)^\top \Sigma^{(m)}_{u,k,t\mid t-1}\phi(\mathbf{x}_t) + R_{m,k}.
\end{equation}

\paragraph{Exploitation score: predictive cost and gap.}
Recall the realized cost \(C_{t,k}=\psi(e_{t,k})+\beta_k\), where \(\beta_k\ge 0\) is the known query
fee.
In practice (and in our experiments), we use squared loss,
\begin{equation}
\label{eq:exp_squared_loss}
\psi(u)=u^2,
\end{equation}
and we will simplify expressions accordingly; nothing in the \((z_t,\mathbf{g}_t)\)-information score
depends on this choice.
Define the predictive (virtual) cost random variable
\begin{equation}
\label{eq:exp_virtual_cost}
C_{t,k}^{\mathrm{pred}}
\coloneqq
\psi(e_{t,k}^{\mathrm{pred}})+\beta_k,
\qquad k\in\mathcal{E}_t,
\end{equation}
with conditional mean
\begin{equation}
\label{eq:exp_mean_cost}
\widehat{c}_t(k)\coloneqq \mathbb{E}\!\left[C_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right]
=
\mathbb{E}\!\left[\psi(e_{t,k}^{\mathrm{pred}})\,\middle|\,\mathcal{F}_t\right]+\beta_k.
\end{equation}
Let \(k_t^{\mathrm{pred}}\in\arg\min_{k\in\mathcal{E}_t}\widehat{c}_t(k)\) and define the predictive gap
\begin{equation}
\label{eq:exp_gap}
\Delta_t(k)\coloneqq \widehat{c}_t(k)-\widehat{c}_t(k_t^{\mathrm{pred}})\ge 0.
\end{equation}

\paragraph{Computing \(\widehat{c}_t(k)\) from per-mode moments.}
From \eqref{eq:exp_g_prior}--\eqref{eq:exp_channel}, the mode-conditioned predictive residual is Gaussian with
\begin{align}
\label{eq:exp_residual_mean}
\mu^{(m)}_{e,t,k}
&\coloneqq
\mathbb{E}\!\left[e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t=m\right]
=
h_{t,k}^\top \mu^{(m)}_{g,t\mid t-1}+b^{(m)}_{t,k},\\
\label{eq:exp_residual_var}
v^{(m)}_{e,t,k}
&\coloneqq
\mathrm{Var}\!\left(e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t=m\right)
=
h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}+s^{(m)}_{t,k}.
\end{align}
Let \(\bar{w}_t^{(m)}=\mathbb{P}(z_t=m\mid\mathcal{F}_t)\).
Then \(p(e_{t,k}\mid\mathcal{F}_t)=\sum_{m=1}^M \bar{w}_t^{(m)}\,\mathcal{N}(\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k})\).
For general \(\psi\),
\begin{equation}
\label{eq:exp_cost_mix}
\mathbb{E}\!\left[\psi(e_{t,k}^{\mathrm{pred}})\,\middle|\,\mathcal{F}_t\right]
=
\sum_{m=1}^M \bar{w}_t^{(m)}\,
\mathbb{E}\!\left[\psi(E)\right]_{E\sim\mathcal{N}(\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k})}.
\end{equation}
In the squared-loss case \(\psi(e)=e^2\) from \eqref{eq:exp_squared_loss}, we have
\(\mathbb{E}[E^2]=v+\mu^2\), hence
\begin{equation}
\label{eq:exp_square_loss_mix}
\widehat{c}_t(k)
=
\left(\sum_{m=1}^M \bar{w}_t^{(m)}\big(v^{(m)}_{e,t,k}+(\mu^{(m)}_{e,t,k})^2\big)\right)+\beta_k.
\end{equation}

\paragraph{Learning score: information about \((z_t,\mathbf{g}_t)\).}
Define the \((z_t,\mathbf{g}_t)\)-information gain of querying expert \(k\) by
\begin{equation}
\label{eq:exp_ig_zg_def}
\mathrm{IG}^{(z,g)}_t(k)
\coloneqq
\mathcal{I}\!\left((z_t,\mathbf{g}_t);\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right).
\end{equation}
By the chain rule,
\begin{align}
\label{eq:exp_ig_zg_chain}
\mathrm{IG}^{(z,g)}_t(k)
&=
\mathcal{I}\!\left(z_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)
+
\mathcal{I}\!\left(\mathbf{g}_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t\right)\\
&=
\underbrace{\mathcal{I}\!\left(z_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)}_{\text{mode-identification}}
+
\underbrace{\sum_{m=1}^M \bar{w}_t^{(m)}\,
\mathcal{I}\!\left(\mathbf{g}_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t=m\right)}_{\text{shared-factor refinement}}.
\end{align}
The second term admits a closed form per mode; the first term is a 1D Gaussian-mixture information
quantity that can be computed accurately with light Monte Carlo.

\paragraph{Closed form: \(\mathcal{I}(\mathbf{g}_t;e_{t,k}^{\mathrm{pred}}\mid \mathcal{F}_t,z_t=m)\).}
Fix \(z_t=m\).
Let \(G\coloneqq \mathbf{g}_t\) and \(Y\coloneqq e_{t,k}^{\mathrm{pred}}\).
Equation \eqref{eq:exp_channel} implies the affine Gaussian channel
\(
Y=h_{t,k}^\top G+b^{(m)}_{t,k}+\varepsilon
\)
with \(\varepsilon\sim\mathcal{N}(0,s^{(m)}_{t,k})\) independent of \(G\).
Then
\begin{equation}
\label{eq:exp_ig_g_mode}
\mathcal{I}\!\left(\mathbf{g}_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t=m\right)
=
\frac12\log\!\left(1+\frac{h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}}{s^{(m)}_{t,k}}\right).
\end{equation}

\paragraph{Monte Carlo: \(\mathcal{I}(z_t;e_{t,k}^{\mathrm{pred}}\mid\mathcal{F}_t)\) for a Gaussian mixture.}
Let \(p_m(e)\coloneqq p(e_{t,k}^{\mathrm{pred}}=e\mid \mathcal{F}_t,z_t=m)=\mathcal{N}(e;\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k})\) and
\(
p_{\mathrm{mix}}(e)\coloneqq \sum_{m=1}^M \bar{w}_t^{(m)}p_m(e).
\)
Then
\begin{align}
\label{eq:exp_iz_mc}
\mathcal{I}\!\left(z_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)
&=
\sum_{m=1}^M \bar{w}_t^{(m)}\,\mathrm{KL}\!\left(p_m\ \middle\|\ p_{\mathrm{mix}}\right)\\
&=
\sum_{m=1}^M \bar{w}_t^{(m)}\,
\mathbb{E}_{E\sim p_m}\!\left[\log p_m(E)-\log p_{\mathrm{mix}}(E)\right].
\end{align}
This suggests the estimator (with \(S\) samples per mode):
\begin{equation}
\label{eq:exp_iz_estimator}
\widehat{\mathcal{I}}_t^{(z)}(k)
\coloneqq
\sum_{m=1}^M \bar{w}_t^{(m)}\left(\frac{1}{S}\sum_{s=1}^S \Big[\log p_m(E_{m,s})-\log p_{\mathrm{mix}}(E_{m,s})\Big]\right),
\qquad
E_{m,s}\overset{\text{iid}}{\sim}\mathcal{N}(\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k}).
\end{equation}

\paragraph{Stable evaluation of \(\log p_{\mathrm{mix}}(e)\).}
Compute Gaussian log-densities via
\begin{equation}
\label{eq:exp_logpdf_gauss}
\log \mathcal{N}(e;\mu,v)
=
-\frac12\log(2\pi v)-\frac{(e-\mu)^2}{2v}.
\end{equation}
Define \(\ell_m(e)\coloneqq \log \bar{w}_t^{(m)}+\log \mathcal{N}(e;\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k})\).
Then compute \(\log p_{\mathrm{mix}}(e)\) by a stable log-sum-exp:
\begin{equation}
\label{eq:exp_logmix_lse}
\log p_{\mathrm{mix}}(e)
=
\log\!\left(\sum_{m=1}^M e^{\ell_m(e)}\right)
=
a(e)+\log\!\left(\sum_{m=1}^M e^{\ell_m(e)-a(e)}\right),
\qquad
a(e)\coloneqq \max_{m\in\{1,\dots,M\}} \ell_m(e).
\end{equation}

\paragraph{Final \((z_t,\mathbf{g}_t)\)-information gain.}
Combine \eqref{eq:exp_ig_zg_chain}, \eqref{eq:exp_ig_g_mode}, and \eqref{eq:exp_iz_estimator}:
\begin{equation}
\label{eq:exp_ig_zg_final}
\widehat{\mathrm{IG}}^{(z,g)}_t(k)
\coloneqq
\widehat{\mathcal{I}}_t^{(z)}(k)
+
\sum_{m=1}^M \bar{w}_t^{(m)}\,
\frac12\log\!\left(1+\frac{h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}}{s^{(m)}_{t,k}}\right).
\end{equation}

\paragraph{Action selection rules (direct, non-randomized).}
With \(\Delta_t(k)\) and \(\widehat{\mathrm{IG}}^{(z,g)}_t(k)\) computed for all \(k\in\mathcal{E}_t\), two
simple direct policies are:
\begin{align}
\label{eq:exp_det_ids_zg}
\text{(ratio / IDS-style)}\qquad
I_t &\in \arg\min_{k\in\mathcal{E}_t}\ \frac{\Delta_t(k)^2}{\widehat{\mathrm{IG}}^{(z,g)}_t(k)},\\
\label{eq:exp_additive_zg}
\text{(additive / MI-bonus)}\qquad
I_t &\in \arg\min_{k\in\mathcal{E}_t}\ \widehat{c}_t(k)-\lambda_t\,\widehat{\mathrm{IG}}^{(z,g)}_t(k).
\end{align}
For \eqref{eq:exp_det_ids_zg}, interpret the ratio as \(+\infty\) when \(\widehat{\mathrm{IG}}^{(z,g)}_t(k)=0\) and
\(\Delta_t(k)>0\); if \(\widehat{\mathrm{IG}}^{(z,g)}_t(k)=0=\Delta_t(k)\), treat the ratio as \(0\).
Equation \eqref{eq:exp_additive_zg} is typically easier to tune: \(\lambda_t\) directly encodes how much
expected cost you are willing to pay per nat/bit of information about \((z_t,\mathbf{g}_t)\).

\paragraph{Implementation map (directly translatable to code).}
At round \(t\), a straightforward implementation can be organized into the following pure functions:
\begin{itemize}
\item \texttt{channel\_params(k,m)} \(\to (h_{t,k},b^{(m)}_{t,k},s^{(m)}_{t,k})\) from \eqref{eq:exp_channel_params};
\item \texttt{residual\_moments(k,m)} \(\to (\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k})\) from \eqref{eq:exp_residual_mean}--\eqref{eq:exp_residual_var};
\item \texttt{logpdf\_normal(e,mu,var)} using \eqref{eq:exp_logpdf_gauss};
\item \texttt{logpdf\_mix(e,weights,mu[1:M],var[1:M])} using the log-sum-exp in \eqref{eq:exp_logmix_lse};
\item \texttt{estimate\_I\_z(k,S)} implementing \eqref{eq:exp_iz_estimator};
\item \texttt{score(k)} computing \(\widehat{\mathrm{IG}}^{(z,g)}_t(k)\) by \eqref{eq:exp_ig_zg_final};
\item \texttt{select\_action(scores,costs)} using \eqref{eq:exp_det_ids_zg} or \eqref{eq:exp_additive_zg}.
\end{itemize}

\paragraph{Alternative baselines: Bayes-UCB and posterior sampling.}
It can be very informative to benchmark against exploration rules that are widely used in Bayesian
bandits and do not require an explicit information-gain computation.
In our setting, they plug directly into the predictive cost random variable \(C^{\mathrm{pred}}_{t,k}\)
from \eqref{eq:exp_virtual_cost}.

\paragraph{Learning-to-Defer baselines (oracle/full feedback).}
Our L2D and L2D-SW baselines use full-feedback losses from all \emph{available} experts at each time
step, i.e., \(\{\ell_{t,k}: k\in\mathcal{E}_t\}\). This information is not observed under bandit
feedback, so these methods are reported only as oracle baselines (labeled as full-feedback in
figures/tables) and are excluded from bandit comparisons.

\subparagraph{Bayes-UCB (for costs: a Bayesian LCB rule).}
For losses/costs, the natural analogue of UCB is a \emph{lower} credible bound on the cost.
Let \(F_{t,k}(c)\coloneqq \mathbb{P}(C^{\mathrm{pred}}_{t,k}\le c\mid \mathcal{F}_t)\) be the conditional
cdf of the predictive cost and define the \(\alpha\)-quantile
\begin{equation}
\label{eq:exp_bayes_ucb_quantile}
Q_{t}(k;\alpha)
\coloneqq
\inf\left\{c\in\mathbb{R}: F_{t,k}(c)\ge \alpha\right\}.
\end{equation}
Given a confidence schedule \(\alpha_t\in(0,1)\) that decays with \(t\) (e.g., \(\alpha_t=1/t\) or \(\alpha_t=1/(t\log^2 t)\)),
the Bayes-UCB (LCB) decision rule is
\begin{equation}
\label{eq:exp_bayes_ucb_rule}
I_t \in \arg\min_{k\in\mathcal{E}_t}\ Q_t(k;\alpha_t).
\end{equation}
Intuition: \eqref{eq:exp_bayes_ucb_rule} chooses an expert that looks good under an optimistic
assessment of its cost (a low quantile), thereby naturally favoring experts with large posterior
uncertainty when they could plausibly be very good.

\subparagraph{Computing \(Q_t(k;\alpha)\) under the IMM predictive model.}
With squared loss, \(C^{\mathrm{pred}}_{t,k}=(e^{\mathrm{pred}}_{t,k})^2+\beta_k\) is a nonlinear
transformation of a Gaussian mixture, so closed-form quantiles are not available in general.
However, quantiles are easy to estimate by Monte Carlo using the same per-mode predictive objects as
Algorithm~\ref{alg:zg_information_exploration}:
\begin{enumerate}
\item draw a mode \(\tilde z\sim \mathrm{Cat}((\bar{w}_t^{(m)})_{m=1}^M)\);
\item draw \(\tilde{\mathbf{g}}\sim \mathcal{N}(\mu^{(\tilde z)}_{g,t\mid t-1},\Sigma^{(\tilde z)}_{g,t\mid t-1})\);
\item for each \(k\), draw \(\tilde e_k = h_{t,k}^\top \tilde{\mathbf{g}} + b^{(\tilde z)}_{t,k} + \tilde\varepsilon_k\) with \(\tilde\varepsilon_k\sim\mathcal{N}(0,s^{(\tilde z)}_{t,k})\);
\item set \(\tilde C_k=\psi(\tilde e_k)+\beta_k\).
\end{enumerate}
Repeating \(N\) times yields samples \(\{\tilde C_{k}^{(n)}\}_{n=1}^N\), and \(Q_t(k;\alpha)\) is the empirical
\(\alpha\)-quantile.

\subparagraph{Posterior sampling (Thompson sampling).}
Posterior sampling chooses actions by sampling a plausible world from the current posterior and then
acting optimally in that sampled world.
In our setting, a direct and implementation-friendly one-step variant is \emph{posterior sampling on
predictive costs}:
\begin{align}
\label{eq:exp_ps_cost}
\text{(PS on predictive costs)}\qquad
&(\tilde z_t,\tilde{\mathbf{g}}_t)\sim p(z_t,\mathbf{g}_t\mid\mathcal{F}_t),\quad
\tilde e_{t,k}=h_{t,k}^\top \tilde{\mathbf{g}}_t + b^{(\tilde z_t)}_{t,k} + \tilde\varepsilon_{t,k},\ \ \tilde\varepsilon_{t,k}\sim \mathcal{N}(0,s^{(\tilde z_t)}_{t,k}),\\
&I_t \in \arg\min_{k\in\mathcal{E}_t}\ \psi(\tilde e_{t,k})+\beta_k.
\end{align}
This rule preserves the \emph{shared-factor coupling} across experts because all sampled residuals are
generated using the same \((\tilde z_t,\tilde{\mathbf{g}}_t)\).
If one prefers a deterministic decision conditional on sampled latents, one can instead replace
\(\psi(\tilde e_{t,k})\) by the conditional predictive expectation
\(\mathbb{E}[\psi(E)]\) with \(E\sim \mathcal{N}(h_{t,k}^\top\tilde{\mathbf{g}}_t+b^{(\tilde z_t)}_{t,k},s^{(\tilde z_t)}_{t,k})\).
Under squared loss \(\psi(e)=e^2\), this yields the closed form
\begin{equation}
\label{eq:exp_ps_squared_det}
\mathbb{E}\!\left[E^2\right]
=
s^{(\tilde z_t)}_{t,k}+\big(h_{t,k}^\top\tilde{\mathbf{g}}_t+b^{(\tilde z_t)}_{t,k}\big)^2,
\qquad
I_t \in \arg\min_{k\in\mathcal{E}_t}\ \left(s^{(\tilde z_t)}_{t,k}+\big(h_{t,k}^\top\tilde{\mathbf{g}}_t+b^{(\tilde z_t)}_{t,k}\big)^2+\beta_k\right),
\end{equation}
which avoids sampling \(\tilde\varepsilon_{t,k}\) and reduces Monte Carlo variance.

\begin{algorithm}[t]
\caption{Bayes-UCB and posterior sampling at round \(t\) (implementation templates)}
\label{alg:bayes_ucb_ps_templates}
\begin{algorithmic}[1]
\REQUIRE Predictive objects from the IMM-factorized SLDS: \(\bar{w}_t^{(m)}\), \((\mu^{(m)}_{g,t\mid t-1},\Sigma^{(m)}_{g,t\mid t-1})\), and \((h_{t,k},b^{(m)}_{t,k},s^{(m)}_{t,k})\).
\REQUIRE Loss \(\psi\), fees \((\beta_k)_{k\in\mathcal{E}_t}\), Bayes-UCB parameters \((\alpha_t,N)\).
\STATE \textbf{Bayes-UCB (LCB) via Monte Carlo quantiles:}
\FOR{\(n=1,\dots,N\)}
    \STATE Draw \(\tilde z^{(n)}\sim \mathrm{Cat}((\bar{w}_t^{(m)})_{m=1}^M)\) and \(\tilde{\mathbf{g}}^{(n)}\sim \mathcal{N}(\mu^{(\tilde z^{(n)})}_{g,t\mid t-1},\Sigma^{(\tilde z^{(n)})}_{g,t\mid t-1})\).
    \FOR{each \(k\in\mathcal{E}_t\)}
        \STATE Draw \(\tilde e_{k}^{(n)}=h_{t,k}^\top \tilde{\mathbf{g}}^{(n)} + b^{(\tilde z^{(n)})}_{t,k} + \tilde\varepsilon\), with \(\tilde\varepsilon\sim \mathcal{N}(0,s^{(\tilde z^{(n)})}_{t,k})\).
        \STATE Set \(\tilde C_{k}^{(n)}\leftarrow \psi(\tilde e_{k}^{(n)})+\beta_k\).
    \ENDFOR
\ENDFOR
\FOR{each \(k\in\mathcal{E}_t\)}
    \STATE Set \(Q_t(k;\alpha_t)\leftarrow\) empirical \(\alpha_t\)-quantile of \(\{\tilde C_k^{(n)}\}_{n=1}^N\).
\ENDFOR
\STATE Choose \(I_t\in\arg\min_k Q_t(k;\alpha_t)\).
\STATE \textbf{Posterior sampling on predictive costs:}
\STATE Draw \(\tilde z\sim \mathrm{Cat}((\bar{w}_t^{(m)})_{m=1}^M)\) and \(\tilde{\mathbf{g}}\sim \mathcal{N}(\mu^{(\tilde z)}_{g,t\mid t-1},\Sigma^{(\tilde z)}_{g,t\mid t-1})\).
\FOR{each \(k\in\mathcal{E}_t\)}
    \STATE Draw \(\tilde e_{t,k}=h_{t,k}^\top\tilde{\mathbf{g}}+b^{(\tilde z)}_{t,k}+\tilde\varepsilon_{t,k}\), with \(\tilde\varepsilon_{t,k}\sim\mathcal{N}(0,s^{(\tilde z)}_{t,k})\).
    \STATE Set \(\tilde C_{t,k}=\psi(\tilde e_{t,k})+\beta_k\).
\ENDFOR
\STATE Choose \(I_t\in\arg\min_k \tilde C_{t,k}\).
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
\caption{\((z_t,\mathbf{g}_t)\)-information exploration at round \(t\)}
\label{alg:zg_information_exploration}
\begin{algorithmic}[1]
\REQUIRE \(\mathcal{F}_t\), available experts \(\mathcal{E}_t\), feature map \(\phi(\mathbf{x}_t)\), predictive weights \(\bar{w}_t^{(m)}\).
\REQUIRE Per-mode predictive moments for \(\mathbf{g}_t\): \((\mu^{(m)}_{g,t\mid t-1},\Sigma^{(m)}_{g,t\mid t-1})\).
\REQUIRE Per-mode predictive moments for each expert's idiosyncratic state: \((\mu^{(m)}_{u,k,t\mid t-1},\Sigma^{(m)}_{u,k,t\mid t-1})\).
\REQUIRE Fees \((\beta_k)_k\), loss \(\psi\), and Monte Carlo budget \(S\).
\FOR{each \(k\in\mathcal{E}_t\)}
    \FOR{each mode \(m\in\{1,\dots,M\}\)}
        \STATE Compute \(h_{t,k},b^{(m)}_{t,k},s^{(m)}_{t,k}\) from \eqref{eq:exp_channel_params}.
        \STATE Compute \(\mu^{(m)}_{e,t,k},v^{(m)}_{e,t,k}\) from \eqref{eq:exp_residual_mean}--\eqref{eq:exp_residual_var}.
        \STATE Compute \(\mathrm{IG}^{(m)}_{g}(k)=\frac12\log\!\left(1+\frac{h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}}{s^{(m)}_{t,k}}\right)\) from \eqref{eq:exp_ig_g_mode}.
    \ENDFOR
    \STATE Compute \(\widehat{c}_t(k)\) (e.g., \eqref{eq:exp_cost_mix}, or \eqref{eq:exp_square_loss_mix} if \(\psi(e)=e^2\)).
    \STATE Estimate \(\widehat{\mathcal{I}}^{(z)}_t(k)\) via \eqref{eq:exp_iz_estimator} using \(\log p_{\mathrm{mix}}\) from \eqref{eq:exp_logmix_lse}.
    \STATE Set \(\widehat{\mathrm{IG}}^{(z,g)}_t(k)\) via \eqref{eq:exp_ig_zg_final}.
\ENDFOR
\STATE Compute \(k_t^{\mathrm{pred}}\in\arg\min_{k\in\mathcal{E}_t}\widehat{c}_t(k)\) and \(\Delta_t(k)\) via \eqref{eq:exp_gap}.
\STATE Select \(I_t\) using either \eqref{eq:exp_det_ids_zg} or \eqref{eq:exp_additive_zg}.
\RETURN \(I_t\).
\end{algorithmic}
\end{algorithm}

\subsubsection{Information Gain for Idiosyncratic States}
\label{sec:ig_idiosyncratic}

For expert-specific exploration, it can be useful to score the information gained about the
idiosyncratic state \(\mathbf{u}_{t,k}\) in addition to \((z_t,\mathbf{g}_t)\). Define
\begin{equation}
\label{eq:exp_ig_zgu_def}
\mathrm{IG}^{(z,g,u)}_t(k)
\coloneqq
\mathcal{I}\!\left((z_t,\mathbf{g}_t,\mathbf{u}_{t,k});\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right).
\end{equation}
By the chain rule,
\begin{equation}
\label{eq:exp_ig_zgu_chain}
\mathrm{IG}^{(z,g,u)}_t(k)
=
\mathcal{I}\!\left(z_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)
+
\mathcal{I}\!\left((\mathbf{g}_t,\mathbf{u}_{t,k});\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t\right).
\end{equation}
For a fixed mode \(z_t=m\), the factorized predictive belief gives independent Gaussians
\(\mathbf{g}_t\sim\mathcal{N}(\mu^{(m)}_{g,t\mid t-1},\Sigma^{(m)}_{g,t\mid t-1})\) and
\(\mathbf{u}_{t,k}\sim\mathcal{N}(\mu^{(m)}_{u,k,t\mid t-1},\Sigma^{(m)}_{u,k,t\mid t-1})\).
The observation channel can be written as
\[
e_{t,k}^{\mathrm{pred}}
=
h_{t,k}^\top \mathbf{g}_t + \phi(\mathbf{x}_t)^\top \mathbf{u}_{t,k} + \varepsilon,
\qquad
\varepsilon\sim\mathcal{N}(0,R_{m,k}),
\]
so for a scalar Gaussian channel,
\begin{equation}
\label{eq:exp_ig_gu_mode}
\mathcal{I}\!\left((\mathbf{g}_t,\mathbf{u}_{t,k});\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t,z_t=m\right)
=
\frac12\log\!\left(1+\frac{h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}+\phi(\mathbf{x}_t)^\top \Sigma^{(m)}_{u,k,t\mid t-1}\phi(\mathbf{x}_t)}{R_{m,k}}\right).
\end{equation}
Thus,
\begin{equation}
\label{eq:exp_ig_zgu_final}
\mathrm{IG}^{(z,g,u)}_t(k)
=
\mathcal{I}\!\left(z_t;\ e_{t,k}^{\mathrm{pred}}\,\middle|\,\mathcal{F}_t\right)
+
\sum_{m=1}^M \bar{w}_t^{(m)}\,
\frac12\log\!\left(1+\frac{h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}+\phi(\mathbf{x}_t)^\top \Sigma^{(m)}_{u,k,t\mid t-1}\phi(\mathbf{x}_t)}{R_{m,k}}\right).
\end{equation}

\paragraph{Relation to \((z_t,\mathbf{g}_t)\)-information.}
Using \(s^{(m)}_{t,k}=\phi(\mathbf{x}_t)^\top \Sigma^{(m)}_{u,k,t\mid t-1}\phi(\mathbf{x}_t)+R_{m,k}\),
the mode-conditioned term in \eqref{eq:exp_ig_gu_mode} decomposes as
\[
\frac12\log\!\left(1+\frac{h_{t,k}^\top \Sigma^{(m)}_{g,t\mid t-1} h_{t,k}}{s^{(m)}_{t,k}}\right)
\;+\;
\frac12\log\!\left(1+\frac{\phi(\mathbf{x}_t)^\top \Sigma^{(m)}_{u,k,t\mid t-1}\phi(\mathbf{x}_t)}{R_{m,k}}\right).
\]
The first term is exactly the shared-factor refinement from \eqref{eq:exp_ig_g_mode}; the second
captures how much a query teaches the expert-specific drift \(\mathbf{u}_{t,k}\). This additional term
improves future predictions for expert \(k\) but, under the factorized model, does not transfer to
other experts.
When expert-specific learning is important, one can replace \(\widehat{\mathrm{IG}}^{(z,g)}_t(k)\)
by \(\widehat{\mathrm{IG}}^{(z,g,u)}_t(k)\) in \eqref{eq:exp_det_ids_zg} or \eqref{eq:exp_additive_zg}.
