\section{Context-Aware Routing in Non-Stationary Environments}

\subsection{Problem Formulation}
\label{sec:preliminaries}

Building on the offline learning-to-defer setup in Section~\ref{sec:background_l2d}, we study
\emph{sequential} expert routing in \emph{non-stationary} time series under \emph{censored (bandit-style)
feedback}  \citep{neu2010online, dani2008stochastic}. The key differences from the offline objective \eqref{eq:l2d_objective} are that (i) at
each round only the queried expert's prediction is observed and (ii) the set of available experts
may vary with time.

\paragraph{Primitives.}
Time is indexed by a finite horizon \(t\in[T]\coloneqq\{1,\dots,T\}\). Let
\((\Omega,\mathcal{F},\mathbb{P})\) be a probability space supporting all random variables. At each
round \(t\), the environment produces a context \(\mathbf{x}_t\in\mathcal{X}\subseteq\mathbb{R}^d\), a
target \(\vy_t\in\mathcal{Y}\subseteq\mathbb{R}^{d_y}\) with \(d_y\ge 1\), and a non-empty finite set
of available expert identities \(\mathcal{E}_t\). In contrast to offline L2D (fixed expert set), we
allow \(\mathcal{E}_t\) to vary with \(t\), capturing both temporary unavailability and newly arriving
experts. The router maintains a time-varying \emph{expert registry} \(\mathcal{K}_t\) containing the
experts for which it keeps per-expert state (in particular, idiosyncratic filtering marginals). We
always ensure \(\mathcal{E}_t\subseteq \mathcal{K}_t\) at decision time \(t\); for scalability,
\(\mathcal{K}_t\) may also discard stale experts and reinitialize them upon re-entry (details in
Section~\ref{sec:registry}). Each identity \(k\in\mathcal{K}_t\) corresponds to a persistent expert
that, when queried at time \(t\), outputs a prediction \(\vhaty_{t,k}\in\mathcal{Y}\).

\paragraph{Residuals, loss, and cost.}
As in \eqref{eq:l2d_cost}, routing to expert \(k\) incurs a prediction error loss plus a query fee.
We define the \emph{potential} residual of expert \(k\) at time \(t\) as
\begin{equation}
\label{eq:realized_residual}
  e_{t,k} \coloneqq \vhaty_{t,k}-\vy_t .
\end{equation}
We model residuals (rather than the nonnegative loss \(\psi(e_{t,k})\)) because the state-space
emission likelihood is defined on \(\mathbb{R}^{d_y}\), allowing the observation model to represent
both positive and negative deviations (over- vs.\ under-prediction) without discarding sign
information.
The incurred (potential) cost is then
\begin{equation}
\label{eq:realized_cost}
  C_{t,k} \coloneqq \psi(e_{t,k}) + \beta_k .
\end{equation}
where \(\psi:\mathbb{R}^{d_y}\to\mathbb{R}_{\ge 0}\) is a known convex loss (e.g., squared error for
\(d_y=1\) or squared norm \(\psi(e)=\lVert e\rVert_2^2\) in general) and \(\beta_k\ge 0\) is a known,
expert-specific query fee. We refer to \((e_{t,k})_{k\in\mathcal{K}_t}\) as the \emph{potential residuals}.

\paragraph{Observation model (censoring).}
At each round, the router selects an expert index \(I_t\in\mathcal{E}_t\). Due to bandit-style
feedback, it observes only the queried prediction \(\vhaty_{t,I_t}\) (and hence only
\(e_{t,I_t}\) and \(C_{t,I_t}\)); for \(k\in\mathcal{E}_t\setminus\{I_t\}\),
\((\vhaty_{t,k},e_{t,k},C_{t,k})\) remain
unobserved. We denote the post-action observation
by
\[
O_t \coloneqq (I_t,\vhaty_{t,I_t},\vy_t).
\]

\paragraph{Filtrations and policies.}
Let \(\mathcal{H}_{t}\coloneqq \big((\mathbf{x}_\tau,\mathcal{E}_\tau,O_\tau)\big)_{\tau=1}^{t}\)
be the interaction history up to the end of round \(t\).
Decisions are non-anticipative, i.e., made before observing \(O_t\).
We define the \emph{decision-time} sigma-algebra (information available before choosing \(I_t\)) as
\begin{equation}
    \mathcal{F}_t \coloneqq \sigma\left(\mathcal{H}_{t-1},\mathbf{x}_t,\mathcal{E}_t\right).
\end{equation}
A policy \(\pi=(\pi_t)_{t=1}^T\) is a sequence of decision rules where
\(\pi_t(\cdot \mid \mathcal{F}_t)\) is an \(\mathcal{F}_t\)-measurable distribution over
\(\mathcal{E}_t\).
The action is sampled as \(I_t \sim \pi_t(\cdot \mid \mathcal{F}_t)\), so that
\(I_t\in\mathcal{E}_t\) almost, surely.

\paragraph{Interaction protocol.}
The process unfolds in discrete rounds. At each time \(t\):
\begin{enumerate}
    \item \textbf{Decision-time revelation:} the environment reveals \((\mathbf{x}_t,\mathcal{E}_t)\),
    thereby determining \(\mathcal{F}_t\).
    \item \textbf{Action:} the router samples \(I_t \sim \pi_t(\cdot \mid \mathcal{F}_t)\).
    \item \textbf{Censored feedback:} the router observes \(O_t=(I_t,\vhaty_{t,I_t},\vy_t)\) and can
    evaluate the realized residual \(e_{t,I_t}\) and cost \(C_{t,I_t}\).
\end{enumerate}

\paragraph{Non-stationarity and exogeneity.}
We do not assume i.i.d.\ data: the joint law of \((\mathbf{x}_t,\mathcal{E}_t,\vy_t)\) may drift over
time (Section~\ref{sec:background_slds}). Concretely, we allow a sequence of time-varying conditional
laws \(\{\mathcal{D}_t\}_{t\ge 1}\) such that
	\begin{equation*}
	    (\mathbf{x}_t,\mathcal{E}_t,\vy_t)\mid \sigma\big((\mathbf{x}_\tau,\mathcal{E}_\tau,\vy_\tau)_{\tau<t}\big)
	    \sim \mathcal{D}_t\left(\cdot \middle| (\mathbf{x}_\tau,\mathcal{E}_\tau,\vy_\tau)_{\tau<t}\right).
	\end{equation*}
This captures non-stationarity (e.g., concept drift or regime shifts). We additionally assume
\emph{exogeneity}: past routing actions affect which expert predictions
are observed, but do not influence the data-generating process.

\paragraph{Objective and myopic Bayes selector.}
Our goal is to sequentially select an available expert \(k \in \mathcal{E}_t\) that balances accuracy
(low \(\psi(e_{t,k})\)) and cost (low \(\beta_k\)). Over the horizon \(t\in[T]\), we seek a policy
\(\pi\) minimizing the expected cumulative cost
\begin{equation}
\label{eq:routing_objective}
    J(\pi) \coloneqq \mathbb{E}\left[\sum_{t=1}^T C_{t,I_t}\right].
\end{equation}
Conditioned on the decision-time information \(\mathcal{F}_t\), the \emph{myopic Bayes selector} chooses an
index minimizing the posterior expected instantaneous cost:
\begin{equation}
\label{eq:bayes_selection}
    k_t^{\star} \in \arg\min_{k\in\mathcal{E}_t} \mathbb{E}\left[C_{t,k} \mid \mathcal{F}_t\right].
\end{equation}
Unlike the offline Bayes rule \eqref{eq:l2d_bayes_rule}, the conditional expectations in
\eqref{eq:bayes_selection} are not directly available because \(C_{t,k}\) is observed only for the
queried expert \citep{neu2010online}. Computing or approximating \eqref{eq:bayes_selection} therefore requires a
predictive model for the latent residuals \((e_{t,k})_{k\in\mathcal{E}_t}\) under censoring and
non-stationarity. In subsequent sections, we introduce a latent-state model that yields tractable
one-step-ahead predictive beliefs \(p(e_{t,k}\mid \mathcal{F}_t)\).

\subsection{Generative Model: Factorized Switching LDS}
\label{sec:generative_model}

Section~\ref{sec:preliminaries} highlights that censored feedback and non-stationarity make the
myopic selector \eqref{eq:bayes_selection} intractable without a predictive belief over \emph{unobserved}
expert residuals.

We therefore model the \emph{potential residuals} \(e_{t,k}=\vhaty_{t,k}-\vy_t\) from
Section~\ref{sec:preliminaries} as emissions of a \textbf{factorized switching linear dynamical system
} \citep{bengio1994input, linderman2016recurrent, hu2024modeling}. The central bottleneck is censoring: at round \(t\) we observe only the queried residual
\(e_t\coloneqq e_{t,I_t}\), while \((e_{t,k})_{k\neq I_t}\) remain counterfactual. A fully independent
per-expert state-space model would therefore propagate most experts essentially ``open-loop''. We
address this by combining (i) a \emph{switching} latent regime \(z_t\) to capture abrupt changes, (ii)
a \emph{shared} global factor \(\mathbf{g}_t\) that couples experts and enables information transfer,
and (iii) \emph{idiosyncratic} expert-specific dynamics \(\mathbf{u}_{t,k}\). For scalability under a
growing registry, our inference later maintains per-expert marginals via a factorized filtering
approximation. The resulting linear-Gaussian structure yields Kalman-style updates and closed-form
information quantities used in our routing rule.

\subsubsection{Latent state hierarchy}
We represent non-stationarity via a two-level hierarchy separating systemic shifts from
expert-specific drifts.

\paragraph{Context-dependent regime switching.}
A discrete regime \(z_t\in\{1,\dots,M\}\) selects the active dynamical law (e.g., ``bull'' vs.\ ``crisis'').
While classical SLDSs often use a time-homogeneous transition matrix, we allow transition
probabilities to depend on the observed context \(\mathbf{x}_t\) (input-driven switching; e.g.,
\citet{bengio1994input}). Let
\(\Pi_\theta(\mathbf{x}_t)\in[0,1]^{M\times M}\) be a row-stochastic matrix with
\begin{equation*}
    \mathbb{P}(z_t=m \mid z_{t-1}=\ell,\mathbf{x}_t)=\Pi_\theta(\mathbf{x}_t)_{\ell m}.
\end{equation*}
This lets the filter incorporate exogenous signals in \(\mathbf{x}_t\) to update its regime belief
before observing the queried residual \(e_t\). This is particularly valuable under censoring: with a
time-homogeneous transition matrix, regime changes can only be detected through the residual stream,
but the router observes only one residual per round. Moreover, the regime belief
\(\bar w_t^{(m)}=\mathbb{P}(z_t=m\mid\mathcal{F}_t)\) directly enters routing through the mixture
predictive law \(p(e_{t,k}\mid\mathcal{F}_t)=\sum_m \bar w_t^{(m)}\,p(e_{t,k}\mid \mathcal{F}_t,z_t=m)\):
contexts that shift mass toward regime \(m\) favor experts with low mode-\(m\) predicted cost, yielding
an interpretable link between \(\mathbf{x}_t\), regimes, and expert specialization.

We parameterize the \emph{logits} of \(\Pi_\theta(\mathbf{x}_t)\) with a low-rank scaled attention
form to control statistical and computational complexity \citep{allyouneed, kossen2021self, mehta2022neural}. Our low-rank parameterization
shares structure across transitions by factoring logits through a low-dimensional bottleneck.
Specifically, we compute \(Q_\theta(\mathbf{x}_t),K_\theta(\mathbf{x}_t)\in\mathbb{R}^{M\times d_{\mathrm{attn}}}\) and set
\[
S(\mathbf{x}_t)\coloneqq \frac{1}{\sqrt{d_{\mathrm{attn}}}}Q_\theta(\mathbf{x}_t)K_\theta(\mathbf{x}_t)^\top,
\]
so that \(\mathrm{rank}(S(\mathbf{x}_t))\le d_{\mathrm{attn}}\). Applying a row-wise softmax yields the
transition matrix:
\begin{equation}
\label{eq:context_transitions}
\mathbb{P}(z_t=m \mid z_{t-1}=\ell,\mathbf{x}_t)
=
\frac{\exp(S_{\ell m}(\mathbf{x}_t))}{\sum_{j=1}^M \exp(S_{\ell j}(\mathbf{x}_t))}.
\end{equation}

\paragraph{Global factor dynamics.}
Under censored feedback, the only way to learn about \emph{unqueried} experts is to exploit structure
that couples them (see Proposition \ref{prop:cross_update}). We therefore introduce a continuous \emph{shared} latent state
\(\mathbf{g}_t\in\mathbb{R}^{d_g}\) representing system-wide conditions (e.g., overall difficulty,
market volatility, sensor drift) that affect many experts simultaneously. Because \(\mathbf{g}_t\)
appears in every expert's residual model, updating \(\mathbf{g}_t\) from the single observed residual
\(e_t=e_{t,I_t}\) immediately sharpens the predictive beliefs for other experts \(k\neq I_t\),
providing the cross-expert information transfer needed for routing.

Conditioned on \(z_t=m\), we model \(\mathbf{g}_t\) with linear-Gaussian dynamics to retain Kalman-style
updates and closed-form predictive quantities used later for exploration:
\begin{equation}
\label{eq:global_dynamics}
\mathbf{g}_t
=
\mathbf{A}^{(g)}_{m}\mathbf{g}_{t-1}+\mathbf{w}^{(g)}_{t},
\qquad
\mathbf{w}^{(g)}_{t}\sim\mathcal{N}(\mathbf{0},\mathbf{Q}^{(g)}_{m}),
\end{equation}
where \(\mathbf{A}^{(g)}_{m}\in\mathbb{R}^{d_g\times d_g}\) and
\(\mathbf{Q}^{(g)}_{m}\in\mathbb{S}^{d_g}_{++}\).
We assume \((\mathbf{w}^{(g)}_{t})_{t}\) are independent across time and independent of all other
process and emission noise terms.

\paragraph{Expert-specific dynamics.}
Not all variation is shared: experts can drift due to recalibration, local overfitting, model
updates, or intermittent failures. We capture these \emph{idiosyncratic} effects with a per-expert
latent state \(\mathbf{u}_{t,k}\in\mathbb{R}^{d_\alpha}\). Conditioned on \(z_t=m\),
\begin{equation}
\label{eq:idiosyncratic_dynamics}
\mathbf{u}_{t,k}
=
\mathbf{A}^{(u)}_{m}\mathbf{u}_{t-1,k}+\mathbf{w}^{(u)}_{t,k},
\quad
\mathbf{w}^{(u)}_{t,k}\sim\mathcal{N}(\mathbf{0},\mathbf{Q}^{(u)}_{m}),
\end{equation}
where conditional on \((z_t)\), the noise terms are independent across experts and time. To maintain
statistical strength under sparse feedback, we share the dynamics parameters
\((\mathbf{A}^{(u)}_{m},\mathbf{Q}^{(u)}_{m})\) across experts. Expert heterogeneity is then expressed
through (i) the expert-specific state realization \(\mathbf{u}_{t,k}\) and (ii) expert-specific
loadings \(\mathbf{B}_k\) in \eqref{eq:alpha_def}, which determine how each expert responds to the
shared factor \(\mathbf{g}_t\).

\paragraph{Reliability composition and residual emission.}
To connect the latent dynamics to observable errors, we introduce a latent \emph{reliability} vector
\(\boldsymbol\alpha_{t,k}\in\mathbb{R}^{d_\alpha}\) that drives the mean residual of expert \(k\) at
time \(t\). We decompose reliability into a component induced by global conditions and an
idiosyncratic drift:
\begin{equation}
\label{eq:alpha_def}
\boldsymbol\alpha_{t,k}\coloneqq \mathbf{B}_k\mathbf{g}_t+\mathbf{u}_{t,k},
\qquad
\mathbf{B}_k\in\mathbb{R}^{d_\alpha\times d_g}.
\end{equation}
Intuitively, \(\mathbf{B}_k\mathbf{g}_t\) captures how expert \(k\)'s errors co-move with the shared
environmental state, while \(\mathbf{u}_{t,k}\) captures deviations unique to expert \(k\).

Given a regime \(z_t=m\) and latent states \((\mathbf{g}_t,\mathbf{u}_{t,k})\), we posit a linear
Gaussian residual model in which the mean residual is an affine function of the latent reliability
\(\boldsymbol\alpha_{t,k}\) through a fixed, context-dependent feature map. This choice plays two
roles: it makes expert performance depend on the observed context \(\mathbf{x}_t\), and it preserves
linear-Gaussian structure so that filtering and information-gain computations remain tractable. We
use a matrix-valued feature map
\(\Phi:\mathcal{X}\to\mathbb{R}^{d_\alpha\times d_y}\) and set
\begin{equation}
\label{eq:residual_emission}
e_{t,k}\mid (z_t=m,\mathbf{g}_t,\mathbf{u}_{t,k},\mathbf{x}_t)
\sim
\mathcal{N}\big(\Phi(\mathbf{x}_t)^\top\boldsymbol\alpha_{t,k},\mathbf{R}_{m,k}\big),
\end{equation}
where \(\mathbf{R}_{m,k}\in\mathbb{S}^{d_y}_{++}\) is an expert- and regime-specific emission noise
covariance. The mean \(\Phi(\mathbf{x}_t)^\top\boldsymbol\alpha_{t,k}\in\mathbb{R}^{d_y}\) represents
a systematic, context-dependent signed error, while \(\mathbf{R}_{m,k}\)
captures irreducible variability that may depend on both the regime and the expert. We assume
emission noise is conditionally independent across experts and time given
\((z_t,\mathbf{g}_t,(\mathbf{u}_{t,k})_k)\). Under bandit feedback, the router observes only the
realized draw from \eqref{eq:residual_emission} for the queried expert,
\(e_t\coloneqq e_{t,I_t}\); all other \(e_{t,k}\) remain counterfactual.

\subsubsection{Implications of the Hierarchy}

\paragraph{Selective information transfer via factorization.}
The hierarchy above is designed so that (i) routing decisions can \emph{generalize across experts}
through the shared factor \(\mathbf{g}_t\), while (ii) expert-specific drifts \(\mathbf{u}_{t,k}\) can
still capture persistent heterogeneity. In the exact Bayesian filter, however, conditioning on the
single observed residual \(e_t=e_{t,I_t}\) couples \(\mathbf{g}_t\) with the entire collection
\((\mathbf{u}_{t,k})_k\), and hence couples experts with each other. Maintaining this full joint
posterior quickly becomes prohibitive as the registry grows.

For scalability, our inference maintains a \emph{factorized} filtering approximation: after each
update, we project the belief onto a family in which (conditional on \(z_t\)) the idiosyncratic
states are independent across experts and independent of \(\mathbf{g}_t\); see
Appendix~\ref{app:cross_covariance} for the full (non-factorized) update and why we avoid it. This
projection discards posterior cross-covariances between experts, but it preserves the key mechanism
needed for routing under censoring: querying a single expert updates the shared factor \(\mathbf{g}_t\),
which then shifts the predictive residual distributions of \emph{all} experts through the loadings
\(\mathbf{B}_k\). The proposition below makes this ``information transfer'' criterion explicit.

\begin{restatable}[Information transfer under a shared factor]{proposition}{propinfo}
\label{prop:cross_update}
Fix \(t\) and \(z_t=m\), and let \(\mathcal{G}_t\coloneqq \sigma(\mathcal{F}_t,I_t,z_t=m)\). Let
\(j\neq I_t\) and let \((e_{t,j}^{\mathrm{pred}},e_{t,I_t}^{\mathrm{pred}})\) denote the one-step-ahead
predictive residuals under \(p(e_{t,\cdot}\mid \mathcal{F}_t,z_t=m)\). Assume that this predictive pair
is jointly Gaussian conditional on \(\mathcal{G}_t\) and that
\(\mathrm{Cov}(e_{t,I_t}^{\mathrm{pred}}\mid \mathcal{G}_t)\) is non-singular (e.g.,
\(\mathbf{R}_{m,I_t}\succ \mathbf{0}\)). Then
\begin{equation*}
    \begin{aligned}
        & \mathbb{E}\left[e_{t,j}^{\mathrm{pred}}\mid e_t,\mathcal{G}_t\right]
=
\mathbb{E}\left[e_{t,j}^{\mathrm{pred}}\mid \mathcal{G}_t\right] \\
& \quad\Longleftrightarrow\quad
\mathrm{Cov}\left(e_{t,j}^{\mathrm{pred}},e_{t,I_t}^{\mathrm{pred}}\mid \mathcal{G}_t\right)=\mathbf{0}.
    \end{aligned}
\end{equation*}
In particular, if the covariance is non-zero, then observing \(e_t=e_{t,I_t}\) updates the posterior
predictive mean of \(e_{t,j}^{\mathrm{pred}}\).
\end{restatable}

We prove Proposition~\ref{prop:cross_update} in Appendix~\ref{app:proof_cross_update}. The transfer is
\emph{selective}: observing the queried residual affects unqueried experts exactly when their predictive
residuals are correlated. In our factorized SLDS, this correlation is induced by the shared factor
\(\mathbf{g}_t\). Under the linear-Gaussian model, the predictive residuals are jointly Gaussian, and
their cross-covariance can be read directly from the shared-factor channel. For example, conditional on
\((\mathcal{F}_t,z_t=m)\),
\(\mathrm{Cov}(e_{t,j}^{\mathrm{pred}},e_{t,i}^{\mathrm{pred}})\) contains the shared-factor term
\[
\Phi(\mathbf{x}_t)^\top \mathbf{B}_j \Sigma^{(m)}_{g,t\mid t-1}\mathbf{B}_{i}^\top \Phi(\mathbf{x}_t),
\]
where \(\Sigma^{(m)}_{g,t\mid t-1}\) is the one-step predictive covariance of \(\mathbf{g}_t\)
under regime \(m\). Thus, querying \(i=I_t\) tightens the predictive distribution of expert \(j\)
whenever the coupling through \(\mathbf{g}_t\) is non-negligible in the directions probed by
\(\Phi(\mathbf{x}_t)\). Concretely, imagine a ``crisis'' regime \(m\) in which experts \(1\) and \(2\)
share the same failure mode (e.g., both degrade when volatility spikes), so that their predictive
residuals are positively correlated. If we query expert \(1\) and observe a large residual \(e_t\),
the filter updates the shared state \(\mathbf{g}_t\) in a direction consistent with ``high difficulty''
under regime \(m\); this automatically shifts the posterior predictive mean/variance of expert \(2\)'s
residual even without querying it. Conversely, if this term is zero (and the idiosyncratic channel is independent),
then under the factorized predictive belief there is no information transfer from \(I_t\) to \(j\) at
time \(t\).

\subsubsection{Exploration via Information-Directed Sampling}
\label{sec:exploration}

Under bandit feedback, greedily selecting the expert with the lowest predicted cost can lead to slow
adaptation: the router may repeatedly query a ``safe'' expert and fail to quickly detect regime
changes or shifts in shared conditions. We therefore use \textbf{Information-Directed Sampling (IDS)}
to trade off exploitation (low predicted cost) and exploration (information about the latent state
that drives future performance).

\paragraph{Exploitation: predicted cost and gap.}
Recall that our model provides a one-step-ahead predictive residual random variable
\(e_{t,k}^{\mathrm{pred}}\sim p(e_{t,k}\mid\mathcal{F}_t)\) for each available expert
\(k\in\mathcal{E}_t\). The (predictive) value gap of choosing \(k\) is
\begin{equation}
\label{eq:model_gap}
\Delta_t(k)
\coloneqq
\bar C_{t,k}^{\mathrm{pred}}-\bar C_{t,k_t^{\mathrm{pred}}}^{\mathrm{pred}}
\ge 0 .
\end{equation}
with the corresponding \emph{predicted cost} $\bar C_{t,k}^{\mathrm{pred}}
\coloneqq
\mathbb{E}\!\left[\psi(e_{t,k}^{\mathrm{pred}})\,\middle|\,\mathcal{F}_t\right]+\beta_k$ and its myopic baseline
$k_t^{\mathrm{pred}} \in \arg\min_{k\in\mathcal{E}_t} \bar C_{t,k}^{\mathrm{pred}}$.


\paragraph{Exploration: informativeness of a query.}
A query is informative if its residual reveals which regime is
active and/or refines the shared factor that couples experts. We quantify this by the mutual
information between the \emph{joint} latent state and the (hypothetical) queried residual:
\begin{equation}
\label{eq:ig_operational}
\mathrm{IG}_t(k)
\coloneqq
\mathcal{I}\left((z_t,\mathbf{g}_t); e_{t,k}^{\mathrm{pred}} \middle| \mathcal{F}_t\right).
\end{equation}
For our linear-Gaussian predictive model, the part of \(\mathrm{IG}_t(k)\) attributable to shared-factor
refinement admits a closed form, while the regime-identification component can be estimated via a
lightweight Monte Carlo routine. We provide the decomposition and computation details in
Remark~\ref{rmk:zg_information} (Appendix) and Algorithm~\ref{alg:router_main}.

\paragraph{Minimizing the information ratio.}
IDS selects the routing action by minimizing the squared information ratio
\begin{equation}
\label{eq:ids_deterministic}
I_t \in \arg\min_{k\in\mathcal{E}_t}\ \frac{\Delta_t(k)^2}{\mathrm{IG}_t(k)}.
\end{equation}
If \(\mathrm{IG}_t(k)=0\), we interpret the ratio as \(+\infty\) unless \(\Delta_t(k)=0\); if all
\(\mathrm{IG}_t(k)=0\), IDS reduces to a myopic choice.
This criterion prioritizes experts that are either near-optimal (small \(\Delta_t(k)\)) or highly
informative about the latent state \((z_t,\mathbf{g}_t)\) (large \(\mathrm{IG}_t(k)\)), accelerating
adaptation to both regime changes and shared-factor drift without auxiliary queries.

\paragraph{Approximate filtering (input-driven IMM).}
To compute the predictive quantities used by IDS, the router maintains an approximate filtering
belief over the current regime \(z_t\), shared factor \(\mathbf{g}_t\), and the idiosyncratic states
\((\mathbf{u}_{t,k})_{k\in\mathcal{K}_t}\) for the maintained registry (Section~\ref{sec:registry}). We
use an \emph{input-driven interacting multiple model (IMM)} recursion:
before the query, we mix mode-conditioned Gaussians using the context-dependent transition matrix
\(\Pi_\theta(\mathbf{x}_t)\) (Eq.~\ref{eq:context_transitions}) to obtain predictive regime weights
\(\bar w_t\); after querying \(I_t\), we apply a Kalman correction in each mode using the single
observed residual \(e_t=e_{t,I_t}\) and reweight modes by their likelihoods
\(w_t^{(m)}\propto p(e_t\mid \mathcal{F}_t,I_t,z_t=m)\,\bar w_t^{(m)}\).
Algorithm~\ref{alg:router_main} and Appendix algorithms provide the full recursion and moment-matching
details.

\subsubsection{Dynamic Registry Management}
\label{sec:registry}

Offline L2D is usually trained against a \emph{fixed} set of experts (a fixed ``catalog'' of deferral
options). In many deployments this assumption fails: expert availability varies and the pool evolves
over time (new models are deployed, providers churn, humans go off-shift). Under a standard L2D
router with a fixed output head, incorporating a \emph{new} expert typically requires modifying the
router parameterization (e.g., adding a new output logit or expert embedding) and then retraining the entire router.
Conversely, when an expert becomes unavailable, a static router can mask it at inference time, but its parameters remain tied to
the full catalog and do not offer a mechanism to \emph{drop} expert-specific components to reclaim
memory/compute or to ``cold-start'' a returning expert with calibrated uncertainty.

Our state-space approach makes this issue explicit: each expert \(k\) carries an idiosyncratic latent
state \(\mathbf{u}_{t,k}\) that must be stored and propagated for prediction. When the pool is large
or long-lived, we cannot maintain \(\mathbf{u}_{t,k}\) for every expert ever encountered. We
therefore treat expert-specific state as a \emph{cache} and manage it online.

Formally, let \(\mathcal{K}_t\) denote the router's \emph{maintained registry}: the set of experts
for which we store per-expert filtering marginals (and hence maintain \(\mathbf{u}_{t,k}\)). The
registry is not cumulative: experts may be removed when stale and re-added upon re-entry. We always
ensure \(\mathcal{E}_t\subseteq \mathcal{K}_t\) at decision time \(t\), so every currently available
expert can be scored; the goal is to keep \(|\mathcal{K}_t|\) bounded without degrading predictions
for retained experts.
Operationally, \(\mathcal{K}_t\) determines which idiosyncratic marginals are stored and propagated by
the filter, and thus which experts can be assigned calibrated predictive beliefs under censoring.

\paragraph{Pruning (dropping stored idiosyncratic marginals).}
Let \(\tau_{\mathrm{last}}(k)\in\{0,1,\dots,t-1\}\) be the last round at which expert \(k\) was queried
(with the convention \(\tau_{\mathrm{last}}(k)=0\) if \(k\) has never been queried).
We call an expert \emph{stale} if it is currently unavailable and has not been queried for more than
\(\Delta_{\max}\) steps, where \(\Delta_{\max}\ge 1\) is a user-chosen staleness horizon:
\begin{equation}
\label{eq:stale_set}
\mathcal{K}^{\mathrm{stale}}_t
\coloneqq
\left\{k\in \mathcal{K}_{t-1}\setminus \mathcal{E}_t:\ t-\tau_{\mathrm{last}}(k)>\Delta_{\max}\right\}.
\end{equation}
We update the registry by first adding currently available experts and then pruning stale ones:
\begin{equation}
\label{eq:registry_update}
\mathcal{K}_t \coloneqq (\mathcal{K}_{t-1}\cup \mathcal{E}_t)\setminus \mathcal{K}^{\mathrm{stale}}_t,
\qquad \mathcal{K}_0=\varnothing .
\end{equation}
Since \(\mathcal{K}^{\mathrm{stale}}_t\subseteq \mathcal{K}_{t-1}\setminus \mathcal{E}_t\) by
construction, \eqref{eq:registry_update} guarantees \(\mathcal{E}_t\subseteq \mathcal{K}_t\).
Operationally, pruning means we stop storing the idiosyncratic filtering marginal(s) associated with
\(\mathbf{u}_{t-1,k}\) (and hence do not propagate it forward) for \(k\in\mathcal{K}^{\mathrm{stale}}_t\).

Crucially, pruning does \emph{not} alter the maintained belief over the retained variables: it is
exact marginalization of dropped coordinates in the filtering distribution.

\begin{restatable}[Pruning does not affect retained experts]{proposition}{invariance}
\label{prop:invariance}
Fix time \(t\) and let \(P_t \subseteq \mathcal{K}_{t-1}\) be any set of experts to be pruned.
Let
\(
q_{t-1\mid t-1}\big(\mathbf{g}_{t-1},(\mathbf{u}_{t-1,\ell})_{\ell\in\mathcal{K}_{t-1}}\big)
\)
denote the (exact or approximate) filtering belief at the end of round \(t-1\) conditioned on the realized history.
Define the pruned belief by marginalization:
\begin{equation*}
    \begin{aligned}
        q^{\mathrm{pr}(P_t)}_{t-1\mid t-1}\big(\mathbf{g}_{t-1},(\mathbf{u}_{t-1,\ell})_{\ell\in\mathcal{K}_{t-1}\setminus P_t}\big)
& \coloneqq \\
\int q_{t-1\mid t-1}\big(\mathbf{g}_{t-1},(\mathbf{u}_{t-1,\ell})_{\ell\in\mathcal{K}_{t-1}}\big)
\prod_{k\in P_t} d\mathbf{u}_{t-1,k}.
    \end{aligned}
\end{equation*}
Then \(q^{\mathrm{pr}(P_t)}_{t-1\mid t-1}\) equals the marginal of \(q_{t-1\mid t-1}\) on the retained variables.
Consequently, after applying the standard SLDS time update to obtain the predictive belief at round \(t\),
the predictive distribution of \(\boldsymbol\alpha_{t,\ell}\) and the one-step predictive law of
\(e_{t,\ell}^{\mathrm{pred}}\) are identical before and after pruning, for every retained \(\ell\notin P_t\).
\end{restatable}

We defer the proof to Appendix~\ref{app:invariance}. If a pruned expert later reappears, we treat it
as a re-entry and reinitialize its idiosyncratic state; \(\Delta_{\max}\) controls the resulting
memory--accuracy trade-off.

\paragraph{Birth and re-entry (informed initialization).}
Let
\(\mathcal{E}^{\mathrm{init}}_t\coloneqq \mathcal{E}_t\setminus \mathcal{K}_{t-1}\)
denote experts that \emph{enter} the maintained registry at time \(t\) (either newly observed or
re-entering after pruning). For each \(j\in\mathcal{E}^{\mathrm{init}}_t\), the filter must
instantiate an idiosyncratic state \(\mathbf{u}_{t,j}\) before the router can assign a calibrated
predictive belief to \(e_{t,j}\). We do so at the \emph{predictive} time (before observing any
residual at round \(t\)).

\emph{Entry prior.} For each entering expert \(j\) and each regime \(m\in[M]\), we assume an
initialization prior
\begin{equation}
\label{eq:birth_prior}
\mathbf{u}_{t-1,j}\mid(z_t=m)\sim \mathcal{N}\big(\mu^{(m)}_{\mathrm{init},j},\Sigma^{(m)}_{\mathrm{init},j}\big),
\qquad m\in[M].
\end{equation}
The parameters \((\mu^{(m)}_{\mathrm{init},j},\Sigma^{(m)}_{\mathrm{init},j})\) can be obtained from
metadata, provider calibration summaries, or recent historical performance; if no side information is
available, they can be set to a conservative default (e.g., zero mean and diagonal covariance).

\emph{Lightweight first update.} To align with our predict-then-correct recursion, we perform a single
idiosyncratic time update under each mode to obtain a predictive state at time \(t\):
\begin{equation}
\label{eq:birth_time_update}
\mathbf{u}_{t,j}\mid(z_t=m)
\sim
\mathcal{N}\big(\mathbf{A}^{(u)}_{m}\mu^{(m)}_{\mathrm{init},j},\ \mathbf{A}^{(u)}_{m}\Sigma^{(m)}_{\mathrm{init},j}\mathbf{A}^{(u)\top}_{m}+\mathbf{Q}^{(u)}_{m}\big),
\qquad m\in[M].
\end{equation}
This ``first update'' does not query the expert; it simply converts an entry-time belief into a
mode-conditioned predictive marginal consistent with \eqref{eq:idiosyncratic_dynamics}.

On entry, we assume the router is also provided with the query fee \(\beta_j\) and a default
emission-noise specification (e.g., a shared \(\mathbf{R}_m\) or an expert-specific \(\mathbf{R}_{m,j}\));
these can be refined online if desired. Finally, to make the expert immediately
\emph{context-aware}, we assume its loading matrix \(\mathbf B_j\) is available at entry (e.g., from
metadata or an embedding model, or initialized from a default prior). This ensures that even a
cold-started expert can benefit from the shared factor \(\mathbf g_t\) inferred from previously
queried experts via \(\boldsymbol\alpha_{t,j}=\mathbf B_j\mathbf g_t+\mathbf u_{t,j}\).

\begin{restatable}[Coupling at birth through the shared factor]{proposition}{transfer}
\label{prop:transfer}
Fix time \(t\) and condition on \((\mathcal{F}_t,z_t=m)\). Under the Factorized SLDS one-step predictive
belief (i.e., with \(\mathrm{Cov}(\mathbf{g}_t,\mathbf{u}_{t,k}\mid\cdot)=\mathbf{0}\) and
\(\mathrm{Cov}(\mathbf{u}_{t,i},\mathbf{u}_{t,j}\mid\cdot)=\mathbf{0}\) for \(i\neq j\)), for any experts \(j\neq k\),
\[
\mathrm{Cov}\left(\boldsymbol\alpha_{t,j},\boldsymbol\alpha_{t,k}\mid \mathcal{F}_t,z_t=m\right)
=
\mathbf{B}_j\Sigma^{(m)}_{g,t\mid t-1}\mathbf{B}_k^\top,
\]
where \(\Sigma^{(m)}_{g,t\mid t-1}\) is the regime-\(m\) one-step predictive covariance of \(\mathbf{g}_t\).
In particular, if the joint predictive law is Gaussian and
\(\mathbf{B}_j\Sigma^{(m)}_{g,t\mid t-1}\mathbf{B}_k^\top\neq \mathbf{0}\),
then \(\boldsymbol\alpha_{t,j}\) and \(\boldsymbol\alpha_{t,k}\) are not independent and hence
\(\mathcal{I}(\boldsymbol\alpha_{t,j};\boldsymbol\alpha_{t,k}\mid \mathcal{F}_t,z_t=m)>0\).
\end{restatable}

We give the proof in Appendix~\ref{app:transfer}.

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[
    node distance=1.5cm and 3cm,
    >=latex,
    thick,
    latent_node/.style={latent, minimum size=1cm},
    obs_node/.style={obs, minimum size=1cm},
    rcurinfo_node/.style={latent, minimum size=1cm},
    action_node/.style={draw, rectangle, minimum size=0.9cm},
    param_edge/.style={->, dashed, color=gray!80}
]

% --- NODES ---
\node[latent_node] (zt_prev) {$z_{t-1}$};
\node[latent_node, right=of zt_prev] (zt) {$z_t$};
\node[latent_node, right=of zt] (zt_next) {$z_{t+1}$};

\node[obs_node, above=1.2cm of zt] (xt) {$\mathbf{x}_t$};

\node[latent_node, below=1.8cm of zt_prev] (gt_prev) {$\mathbf{g}_{t-1}$};
\node[latent_node, right=of gt_prev] (gt) {$\mathbf{g}_t$};

\node[latent_node, below=1.8cm of gt_prev] (ut_prev) {$\mathbf{u}_{t-1,j}$};
\node[latent_node, right=of ut_prev] (ut) {$\mathbf{u}_{t,j}$};

\node[obs_node, below=1.5cm of ut] (lt) {$e_{t,j}$};

% Plate over maintained registry
\plate {experts} {(ut_prev)(ut)(lt)} {$j \in \mathcal{K}_t$};

% Availability and action
\node[obs_node, right=4cm of ut] (Kt) {$\mc{E}_t$};
\node[action_node, below=1.5cm of Kt] (rt) {$I_t$};

% --- EDGES ---
\edge {zt_prev} {zt};
\edge {zt} {zt_next};
\edge {gt_prev} {gt};
\edge {ut_prev} {ut};

\draw[param_edge] (zt) to [bend right=20] node[pos=0.3, midway, right, font=\tiny] {$A^{(g)}_{z_t},Q^{(g)}_{z_t}$} (gt);
\draw[param_edge] (zt.south east) to [bend left=45] node[pos=0.7, right, font=\tiny, xshift=2pt] {$A^{(u)}_{z_t},Q^{(u)}_{z_t}$} (ut.north east);

\draw[->] (gt) to [bend left=45] (lt);
\edge {ut} {lt};

\draw[param_edge]
  (xt)
  to
  node[pos=0.5, right, font=\tiny, xshift=2pt]
  {$\Pi_\theta(\cdot,\cdot\mid \mathbf{x}_t)$}
  (zt);

\draw[->] (xt.east) to [out=0, in=0, looseness=1] node[midway, right, font=\small] {$\Phi(\mathbf{x}_t)$} (lt.east);

\edge {Kt} {rt};

% Selection affects what is observed (not what is generated)
\draw[->, dotted] (rt) -- (lt) node[midway, above, font=\tiny] {reveals};

\end{tikzpicture}
    \caption{Factorized SLDS with bandit feedback and \emph{context-dependent} regime switching:
\(p(z_t\mid z_{t-1},\mathbf{x}_t)\). The plate \(j\in\mathcal{K}_t\) indexes experts whose
idiosyncratic states are stored. Each \(e_{t,j}\) is a \emph{potential} residual, but only \(e_{t,I_t}\)
is revealed at round \(t\).}
    \label{fig:slds_pgm_final}
\end{figure}

