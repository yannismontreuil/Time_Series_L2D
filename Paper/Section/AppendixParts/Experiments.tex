\section{Experiments Details}
\label{sec:experiments-details}

We provide additional details on the experiments of Section~\ref{section:experiments}, including
experimental setup, hyperparameters, and implementation details.

\paragraph{Compared methods.}
We compare our \textbf{L2D-SLDS} router under bandit feedback to the following baselines.
\emph{(i) Ablation:} L2D-SLDS without the shared global factor (set \(d_g=0\)).
\emph{(ii) Contextual bandits:} LinUCB \citep{li2010contextual} and NeuralUCB
\citep{zhou2020neuralcontextualbanditsucbbased} with more details in \ref{subsection:baselines}.

\paragraph{Metric.}
We report the time-averaged cumulative routing cost over horizon \(T\) (Eq.~\eqref{eq:routing_objective}). Concretely, we
compute the estimate
\(
\hat{J}(\pi) \coloneqq \frac{1}{T}\sum_{t=1}^T C_{t,I_t},
\)
where \(C_{t,I_t}\) is the realized cost of deferring to the selected expert at round \(t\). Lower is better.

\subsection{Baselines} \label{subsection:baselines}

\paragraph{Feedback regimes.}
At round \(t\), the router observes \((\mathbf{x}_t,\mathcal{E}_t)\), chooses \(I_t\in\mathcal{E}_t\),
and then observes \((\vhaty_{t,I_t},\vy_t)\), hence the realized residual \(e_t=e_{t,I_t}\) and realized
cost \(C_t=C_{t,I_t}\), where \(C_{t,k}\coloneqq \psi(e_{t,k})+\beta_k\) and
\(e_{t,k}=\vhaty_{t,k}-\vy_t\) (Appendix~\ref{app:notation}).
\emph{Partial feedback} means only \((\vhaty_{t,I_t},\vy_t)\) is observed after acting.

\paragraph{L2D-SLDS and ablation without \(\mathbf{g}_t\).}
Our method is the model-based router of Algorithm~\ref{alg:router_main} under the generative residual
model of Definition~\ref{def:l2d_slds_emission}:
\(
\boldsymbol{\alpha}_{t,k}=\mathbf{B}_k\mathbf{g}_t+\mathbf{u}_{t,k}
\)
and
\(
e_{t,k}\mid(z_t=m,\mathbf{g}_t,\mathbf{u}_{t,k},\mathbf{x}_t)\sim
\mathcal{N}\!\big(\Phi(\mathbf{x}_t)^\top\boldsymbol{\alpha}_{t,k},\mathbf{R}_{m,k}\big)
\)
(\eqref{eq:alpha_def}--\eqref{eq:residual_emission}).
\textbf{L2D-SLDS w/o \(\mathbf{g}_t\)} is the ablation obtained by setting \(d_g=0\) (equivalently
\(\mathbf{B}_k\mathbf{g}_t\equiv \mathbf{0}\) for all \(k\)), so that
\(\boldsymbol{\alpha}_{t,k}=\mathbf{u}_{t,k}\) and the per-expert predictive residuals are conditionally
independent across experts under the factorized belief (no cross-expert transfer through a shared
factor).

\paragraph{Contextual bandits: LinUCB and NeuralUCB (partial and full feedback).}
Both methods operate on the per-round \emph{cost} \(C_{t,k}\) and are implemented as \emph{lower}
confidence bound (LCB) rules since we minimize cost.
Under \emph{full feedback}, the router observes \(\{C_{t,k}\}_{k\in\mathcal{E}_t}\) regardless of which
expert \(I_t\) was selected. Consequently, the usual exploration--exploitation trade-off disappears:
the choice of \(I_t\) does not affect what data is available for learning, so the exploration bonus
can be set to \(0\) (yielding greedy selection) without sacrificing statistical efficiency. We still
state the LCB form below for a unified presentation.

\subparagraph{LinUCB.}
Fix a feature map \(\varphi:\mathbb{R}^d\to\mathbb{R}^p\) (in our experiments, either raw
\(\mathbf{x}_t\) or an RNN embedding).
Assume a linear model for the conditional mean cost of each expert:
\(
\mathbb{E}[C_{t,k}\mid \mathbf{x}_t]\approx \varphi(\mathbf{x}_t)^\top \boldsymbol{\theta}_k
\).
Maintain ridge statistics per expert \(k\), with ridge parameter \(\lambda>0\).
Under \emph{partial feedback}:
\[
\mathbf{V}_{t,k}\coloneqq \lambda \mathbf{I}_p + \sum_{s<t:\ I_s=k} \varphi(\mathbf{x}_s)\varphi(\mathbf{x}_s)^\top,
\qquad
\mathbf{b}_{t,k}\coloneqq \sum_{s<t:\ I_s=k} \varphi(\mathbf{x}_s)C_s,
\qquad
\widehat{\boldsymbol{\theta}}_{t,k}\coloneqq \mathbf{V}_{t,k}^{-1}\mathbf{b}_{t,k}.
\]
where \(C_s=C_{s,I_s}\) is the realized (queried) cost at round \(s\).  At time \(t\), set
\(
\widehat{C}_{t,k}\coloneqq \varphi(\mathbf{x}_t)^\top\widehat{\boldsymbol{\theta}}_{t,k}
\)
and exploration bonus
\(
u_t(k)\coloneqq \alpha_t\sqrt{\varphi(\mathbf{x}_t)^\top\mathbf{V}_{t,k}^{-1}\varphi(\mathbf{x}_t)}.
\)
The decision rule is
\[
I_t \in \arg\min_{k\in\mathcal{E}_t}\ \widehat{C}_{t,k}-u_t(k).
\]
\emph{Partial feedback LinUCB} updates only the chosen arm \(I_t\) (so only \(C_{t,I_t}=C_t\) is observed).

\subparagraph{NeuralUCB.}
Let \(f_{\boldsymbol{\omega}}(\mathbf{x},k)\) be a neural predictor of the conditional mean cost of expert
\(k\) given \(\mathbf{x}\) (we use a shared encoder with a per-expert head).
Define a parameter-gradient feature (to avoid overloading the shared factor \(\mathbf{g}_t\))
\(
\mathbf{h}_{t,k}\coloneqq \nabla_{\boldsymbol{\omega}} f_{\boldsymbol{\omega}}(\mathbf{x}_t,k)\in\mathbb{R}^{p_\omega}.
\)
Maintain a (regularized) Gram matrix. Under \emph{partial feedback}:
\[
\mathbf{A}_t\coloneqq \lambda \mathbf{I}_{p_\omega}
+
\sum_{s<t} \mathbf{h}_{s,I_s}\mathbf{h}_{s,I_s}^\top.
\]

At time \(t\), set
\(
\widehat{C}_{t,k}\coloneqq f_{\boldsymbol{\omega}}(\mathbf{x}_t,k)
\)
and
\(
u_t(k)\coloneqq \alpha_t\sqrt{\mathbf{h}_{t,k}^\top \mathbf{A}_t^{-1}\mathbf{h}_{t,k}}.
\)
The decision rule is
\[
I_t \in \arg\min_{k\in\mathcal{E}_t}\ \widehat{C}_{t,k}-u_t(k).
\]
The network is trained online by stochastic gradient steps on squared error.
\emph{Partial feedback NeuralUCB} uses the loss \((f_{\boldsymbol{\omega}}(\mathbf{x}_t,I_t)-C_t)^2\) (only \(C_t\) observed).

\paragraph{Oracle baseline.}
The (per-round) oracle chooses the best available expert in hindsight:
\[
I_t^{\mathrm{oracle}} \in \arg\min_{k\in\mathcal{E}_t} C_{t,k}.
\]
This is infeasible under partial feedback because \(C_{t,k}\) is not observed for all \(k\), but we
report it as a lower bound on achievable cumulative cost.


\subsection{Synthetic: Regime-Dependent Correlation and Information Transfer}
\label{sec:exp_synthetic_transfer_appendix}

\paragraph{Design goal.}
We construct a controlled routing instance in which (i) experts are \emph{correlated} in a
regime-dependent way, so that observing one expert should update beliefs about others (information
transfer; Proposition~\ref{prop:cross_update}); and (ii) one expert temporarily disappears and
re-enters, so that the maintained registry \(\mathcal{K}_t\) matters (see Appendix).

\paragraph{Environment (regimes, target, context).}
We use \(M=2\) regimes and deterministic switching in blocks of length \(L=150\) over horizon
\(T=3000\) such as $z_t \coloneqq 1 + \left\lfloor \frac{t-1}{L}\right\rfloor \bmod 2$.
The target follows a regime-dependent AR(1), and the context is the one-step lag:
\begin{equation}
\label{eq:exp_tri_cycle_ts_appendix}
y_t = 0.8\,y_{t-1} + d_{z_t} + \eta_t,\qquad \eta_t\sim\mathcal{N}(0,\sigma_y^2).
\end{equation}
We set the router's context to \(x_t\coloneqq y_{t-1}\).
The regime \(z_t\) is latent to the router: the router observes only \(x_t\) (before acting) and the
single queried prediction \(\hat y_{t,I_t}\) (after acting).

\paragraph{Experts and availability.}
We use \(K=4\) experts indexed \(k\in\{0,1,2,3\}\). Expert \(k=1\) is removed from the available set \(\mathcal{E}_t\)
for a contiguous interval \(t\in[2000,2500]\) and then re-enters. Each expert is a one-step forecaster
\(\hat y_{t,k}=f_k(x_t)\) with a shared slope and expert-specific intercept plus noise:
\begin{equation}
\label{eq:exp_synth_expert_rule_appendix}
\hat y_{t,k} \coloneqq 0.8\,y_{t-1} + b_k + \varepsilon_{t,k}.
\end{equation}
We set \((b_0,b_1,b_2,b_3)=(d_1,d_1,d_2,d_2)\), so experts \(\{0,1\}\) are well-calibrated in regime
\(z_t=1\) and experts \(\{2,3\}\) are well-calibrated in regime \(z_t=2\).

To induce \emph{regime-dependent correlation} under bandit feedback, we generate the expert noises as
\[
\varepsilon_{t,k} \coloneqq s_{t,g(k)} + \tilde\varepsilon_{t,k},
\qquad
g(k)\coloneqq 1+\mathbf{1}\{k\in\{2,3\}\},
\]
with independent components \(s_{t,1},s_{t,2},(\tilde\varepsilon_{t,k})_{k}\) and regime-dependent
variances $s_{t,1}\sim\mathcal{N}(0,\sigma_{z_t,1}^2), s_{t,2}\sim\mathcal{N}(0,\sigma_{z_t,2}^2),
\tilde\varepsilon_{t,k}\sim\mathcal{N}(0,\sigma_{\mathrm{id}}^2)$, where \((\sigma_{1,1}^2,\sigma_{1,2}^2)=(\sigma_{\mathrm{hi}}^2,\sigma_{\mathrm{lo}}^2)\) and
\((\sigma_{2,1}^2,\sigma_{2,2}^2)=(\sigma_{\mathrm{lo}}^2,\sigma_{\mathrm{hi}}^2)\) with
\(\sigma_{\mathrm{hi}}^2\gg\sigma_{\mathrm{lo}}^2\). This makes experts \(\{0,1\}\) strongly
correlated in regime \(1\) and experts \(\{2,3\}\) strongly correlated in regime \(2\). We report the MSE of each expert in
Table~\ref{tab:exp_avg_costs}.


\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{4pt}
\caption{Averaged cumulative cost \eqref{eq:routing_objective} on experiment (Section~\ref{sec:exp_synthetic_transfer}).
We report mean \(\pm\) standard error across five runs. Lower is better.}
\label{tab:exp_avg_costs_appendix}
\begin{tabular}{@{}lcc@{}}
\toprule
Method & Averaged Cumulative Cost \\
\midrule
\textbf{L2D-SLDS} & \(\mathbf{13.58 \pm 0.07}\)  \\
L2D-SLDS w/o \(\mathbf{g}_t\) & \(14.68 \pm 0.01\)  \\
\midrule
LinUCB & \(22.94 \pm 0.01\)  \\
NeuralUCB & \(21.92 \pm 0.31\)  \\
Random & \(26.13 \pm 0.25\)   \\
Always expert 0 & \(23.07\)  \\
Always expert 1 & \(28.66\)  \\
Always expert 2 & \(23.05\)  \\
Always expert 3 & \(29.36\)  \\
Oracle & \(9.04\)\\
\bottomrule
\end{tabular}
\end{table}

\textbf{Model Configuration.}
We use $M = 2$ regimes with shared factor dimension $d_g = 1$ and idiosyncratic dimension $d_\alpha = 1$.
The staleness horizon for pruning is $\Delta_{\max} = 500$. We simply run a small warmup of 100 steps before
running L2D-SLDS and UCBs.


\paragraph{Correlation recovery.}
Figure~\ref{fig:exp_synthetic_transfer_regime_estimation} compares the regime-0 loss correlation
structure. The ground truth exhibits a clear block structure: experts \(\{0,1\}\)
form one correlated group while experts \(\{2,3\}\) form another.
Under partial feedback, L2D-SLDS is the only method that reliably recovers this clustering from
partial observations, whereas removing the shared factor \(\mathbf{g}_t\) blurs the separation and
inflates cross-group correlations, consistent with losing cross-expert information transfer. In
contrast, LinUCB/NeuralUCB yield near-degenerate correlation estimates (e.g., overly uniform or
unstable patterns), reflecting that purely discriminative bandit updates do not maintain a coherent
joint belief over experts' latent error processes.

\paragraph{Results and Analysis.}
Table~\ref{tab:exp_avg_costs} shows that \textbf{L2D-SLDS} achieves the lowest routing cost under
partial feedback (\(13.58\pm 0.07\)), improving over LinUCB/NeuralUCB by a wide margin and also
outperforming the best fixed expert. Crucially, it also beats the ablation that removes the shared
factor \(\mathbf{g}_t\) (\(14.68\pm 0.01\)), a \(\approx 7.5\%\) reduction, which directly supports
our central claim: under censoring, modeling a \emph{global} latent component enables
\emph{cross-expert information transfer} from a single queried residual (see Proposition \ref{prop:transfer}). Intuitively, \(\mathbf{g}_t\)
captures regime-dependent common shocks that couple experts; thus, querying one expert updates beliefs
about unqueried experts in a way that contextual bandits (which treat arms largely independently) and
independent per-expert dynamics cannot replicate.

In Appendix, we provide additional experiments that probe this regime-dependent setting in more depth, including detailed
analyses of expert pruning and re-entry.


\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/expert_structure_all}
    \caption{We report the selection frequency of each expert over time as a function of the underlying regime.
The top figure corresponds to the oracle, while the bottom figure shows our approach evaluated against the baselines.
By construction, experts~0 and~1 perform better in regime~1, whereas experts~2 and~3 perform better in regime~2.
Accordingly, a well-adapted router should select experts~0 and~1 more frequently in regime~1 and experts~2 and~3 more frequently in regime~2.
L2D-SLDS (with and without $g_t$) is the only method that captures this structure, closely matching the oracleâ€™s selection behavior.
In contrast, LinUCB and NeuralUCB fail to adapt their selection frequencies to the regimes.}
    \label{fig:expert_structure_all}
\end{figure}

\subsection{ETTh1}
\label{sec:exp_etth1_appendix}

\paragraph{Environment.}
We evaluate L2D-SLDS on the ETTh1 electricity transformer temperature dataset~\cite{haoyietal-informer-2021}, using the oil
temperature (OT) channel as the target \(y_t\). We run the router over the full horizon (\(T=17420\) hourly observations).
Following the synthetic setup, the router uses a one-step lag as context, \(x_t \coloneqq y_{t-1}\) (with \(x_0=0\)).
There is no observed regime annotation for ETTh1; the router observes only \(x_t\) before acting and, after selecting
\(I_t\in\mathcal{E}_t\), it observes the realized outcome \(y_t\) and the single queried prediction \(\hat y_{t,I_t}\) (hence the
queried residual \(e_{t,I_t}\)).

\paragraph{Experts and availability.}
We consider \(K=6\) fixed experts (Table~\ref{tab:experts_etth}). To stress-test dynamic availability and our pruning/re-birth
mechanism, we enforce time-varying expert sets: the strong multi-lag baseline (Expert~4) is available only on the interval
\(t\in[1000,2000]\), while Expert~0 is unavailable on the same interval. This prevents degenerate ``always-pick-the-best''
policies and forces the router to handle both expert arrival/departure (Expert~4) and temporary unavailability with later
return (Expert~0).

\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{4pt}
\caption{Configuration of experts for ETTh1.}
\label{tab:experts_etth_appendix}
\begin{tabular}{@{}lll@{}}
\toprule
Index & Base & Modification \\
\midrule
\textbf{0} & AR(1) & small variance \\
\textbf{1} & AR(1) & large variance \\
\textbf{2} & MLP & trained on early 2/3 of data \\
\textbf{3} & MLP & trained on late 2/3 of data \\
\textbf{4} & AR multi-lag baseline & using lags [1, 24, 168] \\
\textbf{5} & Constant &  always predict 0 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Model Configuration.}
We use $M = 5$ regimes with shared factor dimension $d_g = 2$ and idiosyncratic dimension $d_\alpha = 1$.
The staleness horizon for pruning is $\Delta_{\max} = 250$. The exploration term considers information gain on both global factor $g$ and regime $z$.
Online EM adaptation is enabled with a sliding window of $W = 600$ and updates every 300 steps.


\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{4pt}
\caption{Averaged cumulative cost \eqref{eq:routing_objective} on ETTh1 (Section~\ref{sec:exp_etth1}).
We report the mean $\pm$ standard error over five runs; lower is better.
The averaged cumulative cost is computed both over the full time horizon and, for each expert, only over the periods during which that expert is available.
This explains why Expert~4 attains a low cost despite being available for only a short duration.
Consequently, it is expected that baseline methods exhibit higher averaged costs than Expert~4.}
\label{tab:exp_avg_costs_etth_appendix}
\begin{tabular}{@{}lcc@{}}
\toprule
Method & Averaged Cumulative Cost  \\
\midrule
\textbf{L2D-SLDS} & \(\mathbf{0.80 \pm 0.06}\)  \\
L2D-SLDS w/o \(\mathbf{g}_t\) & \(0.93 \pm 0.08\) \\
\midrule
LinUCB & \(0.84 \pm 0.01\)  \\
NeuralUCB & \(1.09 \pm 0.19\)  \\
Random & \(14.51 \pm 0.73\)  \\
Always expert 0 & \(0.81\)  \\
Always expert 1 & \(1.19\) \\
Always expert 2 & \(0.77\) \\
Always expert 3 & \(1.21\) \\
Always expert 4 & \(0.74\)  \\
Always expert 5 & \(166.65\) \\
Oracle & \(0.24 \pm 0.01\)  \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Results and analysis.}
Table~\ref{tab:exp_avg_costs_etth_appendix} reports the averaged cumulative routing cost. Under \emph{partial feedback}, L2D-SLDS achieves
the lowest cost among adaptive methods that learn online from bandit feedback (\(0.80\pm 0.06\)), improving over LinUCB
(\(0.84\)) and substantially outperforming NeuralUCB (\(1.09\pm 0.19\)). Most importantly, removing the shared factor
\(\mathbf{g}_t\) degrades performance
(\(0.93\pm 0.08\)), a relative increase of \(\approx 15\%\). This gap is consistent with the role of \(\mathbf{g}_t\) under
censoring: ETTh1 exhibits common shocks (e.g., global load/temperature patterns) that affect multiple experts similarly, so a
shared latent component lets a single queried residual update beliefs about \emph{unqueried} experts via the learned
cross-expert dependence.



\subsection{FRED: Treasury Securities at 10-Year Constant Maturity}
\label{subsection_appendix_fred}

\paragraph{Environment.}
We evaluate on the FRED DGS10 series (10-year U.S.\ Treasury constant-maturity yield)~\cite{FRED_DGS10}, using the daily
observations in \texttt{data/FRED\_DGS10.csv} from 1990-01-02 through 2023-12-29 (\(T=8506\)).
The target is \(y_t\coloneqq \text{DGS10}_t\). The router uses a fixed context vector \(x_t\in\mathbb{R}^{10}\) consisting of
yield lags at \(\{1,5,20,60,120,250\}\) days and calendar features for day-of-week and month encoded as sine/cosine pairs.
We z-score normalize each context dimension using the first 2520 observations.
As in all partial-feedback experiments, at each round \(t\) the router observes \((x_t,\mathcal{E}_t)\), chooses \(I_t\), and
then observes \(\hat y_{t,I_t}\) and \(y_t\) (hence the queried residual \(e_{t,I_t}\)).

\paragraph{Experts.}
We use \(K=4\) ridge-regularized linear autoregressive experts (AR) of the form \(\hat y_{t,k}=w_k^\top x_t+b_k\), each trained
offline on a disjoint historical date range and then deployed across the full evaluation horizon. To avoid a single expert
becoming deterministically dominant, we add mild i.i.d.\ Gaussian prediction noise with standard deviation \(0.03\) to each
expert's output. All experts are available at all times (\(\mathcal{E}_t=\{0,1,2,3\}\)).

\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{4pt}
\caption{Configuration of experts for the FRED DGS10 experiment.}
\label{tab:experts_fred_appendix}
\begin{tabular}{@{}lll@{}}
\toprule
Index & Model & Training window \\
\midrule
\textbf{0} & AR (linear ridge on \(x_t\)) & 1990-01-02--2000-12-31 \\
\textbf{1} & AR (linear ridge on \(x_t\)) & 2001-01-01--2007-12-31 \\
\textbf{2} & AR (linear ridge on \(x_t\)) & 2008-01-01--2015-12-31 \\
\textbf{3} & AR (linear ridge on \(x_t\)) & 2016-01-01--2023-12-31 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Model Configuration.}
We use \(M=4\) regimes with shared factor dimension \(d_g=2\) and idiosyncratic dimension \(d_\alpha=10\) (matching the context
dimension). The staleness horizon is \(\Delta_{\max}=4000\), measurement noise is set to \(R=0.01\), and exploration uses the
information gain over both \(\mathbf{g}_t\) and \(z_t\) (mode \texttt{g\_z}). We disable EM adaptation in this experiment.

\paragraph{Results and analysis.}
Table~\ref{tab:exp_avg_var_l2d_fred} reports the averaged cumulative routing cost. Under partial feedback, \textbf{L2D-SLDS}
achieves the lowest cost among adaptive methods (\(0.004327\pm0.000003\)), improving over LinUCB, NeuralUCB, and random routing.
Removing the shared factor slightly degrades performance (\(0.004411\pm0.000011\)), consistent with shared latent structure
providing additional cross-expert signal when only one residual is observed per round.

\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{4pt}
\caption{Averaged cumulative cost \eqref{eq:routing_objective} on the FRED (DGS10) experiment (Appendix~\ref{subsection_appendix_fred}).
We report mean \(\pm\) standard error across five runs; lower is better.}
\label{tab:exp_avg_var_l2d_fred}
\begin{tabular}{@{}lc@{}}
\toprule
Method & Average Cumulative Cost \\
\midrule
\textbf{L2D-SLDS}
& \(\mathbf{0.004327 \pm 0.000003}\) \\
L2D-SLDS w/o \(\mathbf{g}_t\)
& \(0.004411 \pm 0.000011\) \\
\midrule
LinUCB
& \(0.004452 \pm 0.000002\) \\
NeuralUCB
& \(0.004424 \pm 0.000023\) \\
Random
& \(0.004455 \pm 0.000009\) \\
\midrule
Always expert 0
& \(0.004411\) \\
Always expert 1
& \(0.004567\) \\
Always expert 2
& \(0.004505\) \\
Always expert 3
& \(0.004329\) \\
Oracle
& \(0.001754\) \\
\bottomrule
\end{tabular}
\end{table}
